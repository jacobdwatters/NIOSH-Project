{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMH44p9ur8sb92+6+MPOKMv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobdwatters/NIOSH-Project/blob/main/SIG_SUB_Regression_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6jiu0b7x_ihn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import scipy as sp\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA3BtUpn_nZN",
        "outputId": "fbc8e228-200d-4c24-b62b-e507cafd9f81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = ['VIOLATION_OCCUR_DT', 'MINE_ID', 'MINE_TYPE', 'COAL_METAL_IND', 'SIG_SUB', \n",
        "            'INJ_ILLNESS', 'NO_AFFECTED', 'NEGLIGENCE', 'VIOLATOR_VIOLATION_CNT',\n",
        "            'VIOLATOR_INSPECTION_DAY_CNT']\n",
        "TARGETS = ['PROPOSED_PENALTY']"
      ],
      "metadata": {
        "id": "jbswFkyt_n0U"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/My Drive/NIOSH Project/data/violations_processed_after_2010.csv'\n",
        "violation_data = pd.read_csv(path)\n",
        "\n",
        "print('Samples in dataset: ', len(violation_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJGALcVp_rTB",
        "outputId": "09163375-2f08-4b8a-b2f4-7c586b0a497d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples in dataset:  1429135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "significant_data = violation_data[violation_data['SIG_SUB'] == 'Y']\n",
        "print('Significant and substantial samples in dataset: ', len(significant_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JfDWvz_AT6Q",
        "outputId": "4efe37e8-81b3-4c9a-e765-08ba50508520"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Significant and substantial samples in dataset:  342474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare and Split Significant Data"
      ],
      "metadata": {
        "id": "m2YeZ4f3AvXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = ['MINE_TYPE', 'COAL_METAL_IND', 'LIKELIHOOD', \n",
        "            'INJ_ILLNESS', 'NO_AFFECTED', 'NEGLIGENCE', 'VIOLATOR_VIOLATION_CNT',\n",
        "            'VIOLATOR_INSPECTION_DAY_CNT']\n",
        "TARGETS = ['PROPOSED_PENALTY']\n",
        "\n",
        "X = significant_data[FEATURES]\n",
        "y = significant_data[TARGETS]\n",
        "\n",
        "# Define which columns should be encoded vs scaled\n",
        "columns_to_encode = ['MINE_TYPE', 'COAL_METAL_IND', 'LIKELIHOOD', 'INJ_ILLNESS', 'NEGLIGENCE']\n",
        "columns_to_scale  = ['VIOLATOR_VIOLATION_CNT', 'NO_AFFECTED', 'VIOLATOR_INSPECTION_DAY_CNT']\n",
        "\n",
        "# Instantiate encoder/scaler\n",
        "scaler = StandardScaler()\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Scale and Encode Separate Columns\n",
        "scaled_columns  = scaler.fit_transform(X[columns_to_scale])\n",
        "encoded_columns = ohe.fit_transform(X[columns_to_encode])\n",
        "\n",
        "# Concatenate (Column-Bind) Processed Columns Back Together\n",
        "X_pre = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
        "np.nan_to_num(X_pre, copy=False)\n",
        "\n",
        "print('Features shape:', X_pre.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_train shape:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejn4CWIkAuy0",
        "outputId": "a71e88a1-daf7-4916-90ec-97adef4b45a1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (342474, 22)\n",
            "X_train shape: (256855, 22)\n",
            "X_test shape: (85619, 22)\n",
            "y_train shape: (256855, 1)\n",
            "y_train shape: (85619, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desicion Tree Model With AdaBoost\n",
        "Apply hyper parameter tuning using cross-validation and gridsearch."
      ],
      "metadata": {
        "id": "bsVhMezEB_dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators_range = np.arange(2, 11, 2)\n",
        "max_depth_range = [DecisionTreeRegressor(max_depth=x) for x in range(2, 17, 2)]\n",
        "hyper_param_grid = dict(estimator=max_depth_range, n_estimators=n_estimators_range)\n",
        "\n",
        "tree_regressor_adaboost = AdaBoostRegressor()\n",
        "\n",
        "grid = GridSearchCV(tree_regressor_adaboost, hyper_param_grid, cv=5, return_train_score=False, refit=True, n_jobs=-1)\n",
        "grid.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "tree_regressor_adaboost_optimal = grid.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRS12RYmBPdJ",
        "outputId": "4f55b426-379c-41ba-b3bc-5966ca66b7a0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best r2 Score:  0.4983829609149536\n",
            "Best Parameters:  {'estimator': DecisionTreeRegressor(max_depth=12), 'n_estimators': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation Results\n"
      ],
      "metadata": {
        "id": "W09CdIvZTHav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean cross-validated r2 score: ', grid.best_score_)\n",
        "print('Best Parameters: ', grid.best_params_)"
      ],
      "metadata": {
        "id": "5CIk4ZL_StiD",
        "outputId": "1cd067f4-0f33-40e5-e460-c16e8aaca7c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validated r2 score:  0.4983829609149536\n",
            "Best Parameters:  {'estimator': DecisionTreeRegressor(max_depth=12), 'n_estimators': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compute Final Testing Scores"
      ],
      "metadata": {
        "id": "YyHpXsqrLwss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_regressor_adaboost_y_pred_train = tree_regressor_adaboost_optimal.predict(X_train)\n",
        "tree_regressor_adaboost_y_pred_test = tree_regressor_adaboost_optimal.predict(X_test)\n",
        "\n",
        "tree_regressor_adaboost_r_squared_train = r2_score(y_train, tree_regressor_adaboost_y_pred_train)\n",
        "tree_regressor_adaboost_r_squared_test = r2_score(y_test, tree_regressor_adaboost_y_pred_test)\n",
        "\n",
        "tree_regressor_adaboost_mae_train = mean_absolute_error(y_train, tree_regressor_adaboost_y_pred_train)\n",
        "tree_regressor_adaboost_mae_test = mean_absolute_error(y_test, tree_regressor_adaboost_y_pred_test)\n",
        "\n",
        "print('Decision Tree Regression with AdaBoost Scores:')\n",
        "print('Training R^2 = %.3f' % tree_regressor_adaboost_r_squared_train)\n",
        "print('Training MAE = $%.2f' % tree_regressor_adaboost_mae_train)\n",
        "\n",
        "print('\\nTesting R^2 = %.3f' % tree_regressor_adaboost_r_squared_test)\n",
        "print('Testing MAE = $%.2f' % tree_regressor_adaboost_mae_test)"
      ],
      "metadata": {
        "id": "TvTodilbLv9i",
        "outputId": "456297b4-8a2b-4fed-8a1e-0e9f4740ce19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regression with AdaBoost Scores:\n",
            "Training R^2 = 0.748\n",
            "Training MAE = $1004.79\n",
            "\n",
            "Testing R^2 = 0.530\n",
            "Testing MAE = $1154.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Final Model"
      ],
      "metadata": {
        "id": "jwDNxmLpqZZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "filename = '/content/gdrive/My Drive/SIG_SUB_tree_regressor_adaboost_model_final.joblib'\n",
        "dump(tree_regressor_adaboost_optimal, filename)"
      ],
      "metadata": {
        "id": "Ss4_8A1Sin8T",
        "outputId": "24a60f83-66f8-48b3-c4b0-62c6d469f4c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/SIG_SUB_tree_regressor_adaboost_model_final.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Neural Network"
      ],
      "metadata": {
        "id": "nxN3Egj_CDiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 85:\n",
        "    return lr\n",
        "  else: # Drop learning rate after the first 85 epochs\n",
        "    return lr*np.exp(-0.05)"
      ],
      "metadata": {
        "id": "G0-n-ch8CCj4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096*2\n",
        "epochs = 120\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.Input(shape = (len(X_train[0]), ) ))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dense(32, activation=\"relu\"))\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(8, activation=\"relu\"))\n",
        "model.add(layers.Dense(8, activation=\"relu\"))\n",
        "model.add(layers.Dense(8, activation=\"relu\"))\n",
        "model.add(layers.Dense(1, activation=\"linear\"))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
        "                    callbacks=[callback], validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKLIxnJLCKR1",
        "outputId": "54b7fa1c-42f7-4e9b-e312-1a35b24e5685"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "32/32 [==============================] - 2s 25ms/step - loss: 47114180.0000 - val_loss: 48527564.0000 - lr: 0.0100\n",
            "Epoch 2/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 45972520.0000 - val_loss: 42875732.0000 - lr: 0.0100\n",
            "Epoch 3/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 38816668.0000 - val_loss: 36564640.0000 - lr: 0.0100\n",
            "Epoch 4/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 32339162.0000 - val_loss: 30185592.0000 - lr: 0.0100\n",
            "Epoch 5/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 27099322.0000 - val_loss: 25719076.0000 - lr: 0.0100\n",
            "Epoch 6/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 24227474.0000 - val_loss: 23186046.0000 - lr: 0.0100\n",
            "Epoch 7/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 23026070.0000 - val_loss: 23005250.0000 - lr: 0.0100\n",
            "Epoch 8/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 22680308.0000 - val_loss: 22477556.0000 - lr: 0.0100\n",
            "Epoch 9/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 22480274.0000 - val_loss: 22221460.0000 - lr: 0.0100\n",
            "Epoch 10/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 22366674.0000 - val_loss: 22168938.0000 - lr: 0.0100\n",
            "Epoch 11/120\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 22320778.0000 - val_loss: 22025148.0000 - lr: 0.0100\n",
            "Epoch 12/120\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 22174704.0000 - val_loss: 21957948.0000 - lr: 0.0100\n",
            "Epoch 13/120\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 22130094.0000 - val_loss: 21821364.0000 - lr: 0.0100\n",
            "Epoch 14/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 21998726.0000 - val_loss: 21864882.0000 - lr: 0.0100\n",
            "Epoch 15/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 21815724.0000 - val_loss: 21729426.0000 - lr: 0.0100\n",
            "Epoch 16/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 21622618.0000 - val_loss: 21328302.0000 - lr: 0.0100\n",
            "Epoch 17/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 21434980.0000 - val_loss: 21103104.0000 - lr: 0.0100\n",
            "Epoch 18/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 20858348.0000 - val_loss: 20567552.0000 - lr: 0.0100\n",
            "Epoch 19/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 20366000.0000 - val_loss: 20003690.0000 - lr: 0.0100\n",
            "Epoch 20/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 19931710.0000 - val_loss: 19567720.0000 - lr: 0.0100\n",
            "Epoch 21/120\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 19582240.0000 - val_loss: 19598216.0000 - lr: 0.0100\n",
            "Epoch 22/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 19319030.0000 - val_loss: 19201336.0000 - lr: 0.0100\n",
            "Epoch 23/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 19084596.0000 - val_loss: 19349406.0000 - lr: 0.0100\n",
            "Epoch 24/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 18958376.0000 - val_loss: 19087668.0000 - lr: 0.0100\n",
            "Epoch 25/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 18795168.0000 - val_loss: 19017628.0000 - lr: 0.0100\n",
            "Epoch 26/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 18650402.0000 - val_loss: 18794560.0000 - lr: 0.0100\n",
            "Epoch 27/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 18514120.0000 - val_loss: 18770192.0000 - lr: 0.0100\n",
            "Epoch 28/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 18541154.0000 - val_loss: 18721332.0000 - lr: 0.0100\n",
            "Epoch 29/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 18550998.0000 - val_loss: 18710182.0000 - lr: 0.0100\n",
            "Epoch 30/120\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 18396832.0000 - val_loss: 18871026.0000 - lr: 0.0100\n",
            "Epoch 31/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 18275916.0000 - val_loss: 18655824.0000 - lr: 0.0100\n",
            "Epoch 32/120\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 18195216.0000 - val_loss: 18674778.0000 - lr: 0.0100\n",
            "Epoch 33/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 18115010.0000 - val_loss: 18497704.0000 - lr: 0.0100\n",
            "Epoch 34/120\n",
            "32/32 [==============================] - 2s 56ms/step - loss: 18115798.0000 - val_loss: 18661508.0000 - lr: 0.0100\n",
            "Epoch 35/120\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 18142410.0000 - val_loss: 18441546.0000 - lr: 0.0100\n",
            "Epoch 36/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 18000200.0000 - val_loss: 18537980.0000 - lr: 0.0100\n",
            "Epoch 37/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17941010.0000 - val_loss: 18541252.0000 - lr: 0.0100\n",
            "Epoch 38/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 18035106.0000 - val_loss: 18668982.0000 - lr: 0.0100\n",
            "Epoch 39/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17945354.0000 - val_loss: 18560120.0000 - lr: 0.0100\n",
            "Epoch 40/120\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 17898420.0000 - val_loss: 18398942.0000 - lr: 0.0100\n",
            "Epoch 41/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17829184.0000 - val_loss: 18717564.0000 - lr: 0.0100\n",
            "Epoch 42/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 18070656.0000 - val_loss: 18659670.0000 - lr: 0.0100\n",
            "Epoch 43/120\n",
            "32/32 [==============================] - 2s 47ms/step - loss: 17968032.0000 - val_loss: 18426822.0000 - lr: 0.0100\n",
            "Epoch 44/120\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 17755990.0000 - val_loss: 18574690.0000 - lr: 0.0100\n",
            "Epoch 45/120\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 17709384.0000 - val_loss: 18357940.0000 - lr: 0.0100\n",
            "Epoch 46/120\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 17578552.0000 - val_loss: 18290328.0000 - lr: 0.0100\n",
            "Epoch 47/120\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 17578832.0000 - val_loss: 18513886.0000 - lr: 0.0100\n",
            "Epoch 48/120\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 17557192.0000 - val_loss: 18923142.0000 - lr: 0.0100\n",
            "Epoch 49/120\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 17588362.0000 - val_loss: 18461008.0000 - lr: 0.0100\n",
            "Epoch 50/120\n",
            "32/32 [==============================] - 1s 45ms/step - loss: 17577878.0000 - val_loss: 18661302.0000 - lr: 0.0100\n",
            "Epoch 51/120\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 17489098.0000 - val_loss: 18303216.0000 - lr: 0.0100\n",
            "Epoch 52/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 17462634.0000 - val_loss: 18484952.0000 - lr: 0.0100\n",
            "Epoch 53/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 17456862.0000 - val_loss: 18368912.0000 - lr: 0.0100\n",
            "Epoch 54/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 17445450.0000 - val_loss: 18284266.0000 - lr: 0.0100\n",
            "Epoch 55/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 17338416.0000 - val_loss: 18366164.0000 - lr: 0.0100\n",
            "Epoch 56/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17351254.0000 - val_loss: 18749034.0000 - lr: 0.0100\n",
            "Epoch 57/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17339542.0000 - val_loss: 18431638.0000 - lr: 0.0100\n",
            "Epoch 58/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17266206.0000 - val_loss: 18855834.0000 - lr: 0.0100\n",
            "Epoch 59/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17388058.0000 - val_loss: 18362980.0000 - lr: 0.0100\n",
            "Epoch 60/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17148900.0000 - val_loss: 18447380.0000 - lr: 0.0100\n",
            "Epoch 61/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17310106.0000 - val_loss: 18360638.0000 - lr: 0.0100\n",
            "Epoch 62/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17217748.0000 - val_loss: 19049066.0000 - lr: 0.0100\n",
            "Epoch 63/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17436310.0000 - val_loss: 18572224.0000 - lr: 0.0100\n",
            "Epoch 64/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17359436.0000 - val_loss: 18545012.0000 - lr: 0.0100\n",
            "Epoch 65/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17194076.0000 - val_loss: 18474370.0000 - lr: 0.0100\n",
            "Epoch 66/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17168930.0000 - val_loss: 18368100.0000 - lr: 0.0100\n",
            "Epoch 67/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17139030.0000 - val_loss: 18438832.0000 - lr: 0.0100\n",
            "Epoch 68/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17173936.0000 - val_loss: 18443116.0000 - lr: 0.0100\n",
            "Epoch 69/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17057150.0000 - val_loss: 18402452.0000 - lr: 0.0100\n",
            "Epoch 70/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17138644.0000 - val_loss: 19100648.0000 - lr: 0.0100\n",
            "Epoch 71/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17162444.0000 - val_loss: 18572390.0000 - lr: 0.0100\n",
            "Epoch 72/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 17044524.0000 - val_loss: 18384400.0000 - lr: 0.0100\n",
            "Epoch 73/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 17062376.0000 - val_loss: 18360800.0000 - lr: 0.0100\n",
            "Epoch 74/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 17040414.0000 - val_loss: 18558998.0000 - lr: 0.0100\n",
            "Epoch 75/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 16951760.0000 - val_loss: 18522814.0000 - lr: 0.0100\n",
            "Epoch 76/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16989394.0000 - val_loss: 18364314.0000 - lr: 0.0100\n",
            "Epoch 77/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16947118.0000 - val_loss: 18668922.0000 - lr: 0.0100\n",
            "Epoch 78/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 16849908.0000 - val_loss: 18497370.0000 - lr: 0.0100\n",
            "Epoch 79/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 16984086.0000 - val_loss: 18477864.0000 - lr: 0.0100\n",
            "Epoch 80/120\n",
            "32/32 [==============================] - 1s 22ms/step - loss: 16780446.0000 - val_loss: 18382034.0000 - lr: 0.0100\n",
            "Epoch 81/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16953888.0000 - val_loss: 18645226.0000 - lr: 0.0100\n",
            "Epoch 82/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16858956.0000 - val_loss: 18167232.0000 - lr: 0.0100\n",
            "Epoch 83/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 16790566.0000 - val_loss: 18515938.0000 - lr: 0.0100\n",
            "Epoch 84/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 16764513.0000 - val_loss: 18220770.0000 - lr: 0.0100\n",
            "Epoch 85/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16752766.0000 - val_loss: 18527422.0000 - lr: 0.0100\n",
            "Epoch 86/120\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 16778254.0000 - val_loss: 18630946.0000 - lr: 0.0095\n",
            "Epoch 87/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16760616.0000 - val_loss: 18277782.0000 - lr: 0.0090\n",
            "Epoch 88/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16750714.0000 - val_loss: 18392344.0000 - lr: 0.0086\n",
            "Epoch 89/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16577263.0000 - val_loss: 18329714.0000 - lr: 0.0082\n",
            "Epoch 90/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16547718.0000 - val_loss: 18370606.0000 - lr: 0.0078\n",
            "Epoch 91/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16580959.0000 - val_loss: 18409438.0000 - lr: 0.0074\n",
            "Epoch 92/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16426498.0000 - val_loss: 18424898.0000 - lr: 0.0070\n",
            "Epoch 93/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16436162.0000 - val_loss: 18526628.0000 - lr: 0.0067\n",
            "Epoch 94/120\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 16336181.0000 - val_loss: 18106364.0000 - lr: 0.0064\n",
            "Epoch 95/120\n",
            "32/32 [==============================] - 2s 53ms/step - loss: 16349086.0000 - val_loss: 18343522.0000 - lr: 0.0061\n",
            "Epoch 96/120\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 16276711.0000 - val_loss: 18220414.0000 - lr: 0.0058\n",
            "Epoch 97/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 16360795.0000 - val_loss: 18336602.0000 - lr: 0.0055\n",
            "Epoch 98/120\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 16217837.0000 - val_loss: 18350338.0000 - lr: 0.0052\n",
            "Epoch 99/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16290973.0000 - val_loss: 18348642.0000 - lr: 0.0050\n",
            "Epoch 100/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16192327.0000 - val_loss: 18286736.0000 - lr: 0.0047\n",
            "Epoch 101/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16175012.0000 - val_loss: 18354690.0000 - lr: 0.0045\n",
            "Epoch 102/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16199893.0000 - val_loss: 18223670.0000 - lr: 0.0043\n",
            "Epoch 103/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16168790.0000 - val_loss: 18370560.0000 - lr: 0.0041\n",
            "Epoch 104/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16095628.0000 - val_loss: 18258836.0000 - lr: 0.0039\n",
            "Epoch 105/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16106638.0000 - val_loss: 18506380.0000 - lr: 0.0037\n",
            "Epoch 106/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16212398.0000 - val_loss: 18251474.0000 - lr: 0.0035\n",
            "Epoch 107/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16057922.0000 - val_loss: 18341728.0000 - lr: 0.0033\n",
            "Epoch 108/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16045489.0000 - val_loss: 18276314.0000 - lr: 0.0032\n",
            "Epoch 109/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 16002833.0000 - val_loss: 18340240.0000 - lr: 0.0030\n",
            "Epoch 110/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16032309.0000 - val_loss: 18327168.0000 - lr: 0.0029\n",
            "Epoch 111/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 15988977.0000 - val_loss: 18342832.0000 - lr: 0.0027\n",
            "Epoch 112/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 16024901.0000 - val_loss: 18377350.0000 - lr: 0.0026\n",
            "Epoch 113/120\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 15942607.0000 - val_loss: 18380880.0000 - lr: 0.0025\n",
            "Epoch 114/120\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 15962661.0000 - val_loss: 18357882.0000 - lr: 0.0023\n",
            "Epoch 115/120\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 15944891.0000 - val_loss: 18402766.0000 - lr: 0.0022\n",
            "Epoch 116/120\n",
            "32/32 [==============================] - 1s 23ms/step - loss: 15933072.0000 - val_loss: 18308596.0000 - lr: 0.0021\n",
            "Epoch 117/120\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 15931752.0000 - val_loss: 18356708.0000 - lr: 0.0020\n",
            "Epoch 118/120\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 15871600.0000 - val_loss: 18296998.0000 - lr: 0.0019\n",
            "Epoch 119/120\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 15904942.0000 - val_loss: 18322716.0000 - lr: 0.0018\n",
            "Epoch 120/120\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 15875321.0000 - val_loss: 18260684.0000 - lr: 0.0017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('Testing r2 = %.3f' % r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTAbOW6PCP10",
        "outputId": "84ff075e-fcc7-4df5-a041-20c05824ebc6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2676/2676 [==============================] - 9s 3ms/step\n",
            "Testing r2 = 0.591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FykBP4mHCWzo",
        "outputId": "35436461-6a5f-4fb3-e7ff-e7be8febabff"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}