{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'violation_common' from '/home/zack/work/NIOSH-Project/violation_common.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC, RandomOverSampler\n",
    "import numpy as np\n",
    "import violation_common\n",
    "# run this cell after updating violation_common\n",
    "reload(violation_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of data splits\n",
    "\n",
    "First we split into a full training set and a test set. The test set will be used to get an unbiased measure of the final model's performance.\n",
    "\n",
    "```\n",
    "data -> train_full, test\n",
    "```\n",
    "\n",
    "Now we create a version (not a split) of train_full with SMOTE resampling. The original train_full will be used to train models tat didn't make use of SMOTE training during hyperparamter selection. The SMOTE train_full will be used to train model that did (after hyperparam selection as well).\n",
    "\n",
    "```\n",
    "train_smote_full = SMOTE(train_full)\n",
    "```\n",
    "\n",
    "Now we split the train_full dataset in to train_hp and validate_hp sets to train and validate different hyperparam combinations. Keep in mind these are both not resampled.\n",
    "\n",
    "```\n",
    "train_full -> train_hp, validate_hp\n",
    "```\n",
    "\n",
    "Finally we make a version of train_hp that is SMOTE resampled so we can train hyperparams with SMOTE resampled data. Keep in mind we don't create a SMOTE hyperparam validation set since we want to validate hyperparams with the original data distribution.\n",
    "\n",
    "```\n",
    "train_hp_smote = SMOTE(train_hp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = violation_common.get_processed_violation_data()\n",
    "after_2010 = data.query('YEAR_OCCUR > 2010')\n",
    "after_2010.to_csv('data/after_2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test dataset to be consistent between models\n",
    "after_2010 = pd.read_csv('data/after_2010.csv', index_col=0)\n",
    "train, test = train_test_split(after_2010, test_size=0.2, random_state=0)\n",
    "# hyperparameter tuning sets\n",
    "train_hp, validate_hp = train_test_split(train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('data/after_2010_test.csv')\n",
    "train.to_csv('data/after_2010_train_full.csv')\n",
    "train_hp.to_csv('data/after_2010_train_hp.csv')\n",
    "validate_hp.to_csv('data/after_2010_validate_hp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Samples in Train Dataset: 1023606\n",
      "S&S samples after SMOTE: 511803\n",
      "Non-S&S samples after SMOTE: 511803\n",
      "Performing SMOTENC\n"
     ]
    }
   ],
   "source": [
    "# SMOTE for full train dataset (to be used after hyperparameter tuning)\n",
    "\n",
    "n_samples = len(train)\n",
    "n_sig_target = int(n_samples / 2)\n",
    "n_non_sig_target = n_samples - n_sig_target\n",
    "print(f'''N Samples in Train Dataset: {n_samples}\n",
    "S&S samples after SMOTE: {n_sig_target}\n",
    "Non-S&S samples after SMOTE: {n_non_sig_target}''')\n",
    "      \n",
    "# randomly drop neccesary samples from majority class (non-S&S)\n",
    "current_non_sig_n = len(train.query('SIG_SUB == \"N\"'))\n",
    "num_to_drop = current_non_sig_n - n_non_sig_target\n",
    "drop_indices = np.random.choice(train.query('SIG_SUB == \"N\"').index, num_to_drop, replace=False)\n",
    "train_undersampled = train.drop(drop_indices)\n",
    "\n",
    "# oversample with SMOTE\n",
    "categorical_features = ['VIOLATOR_TYPE_CD', 'MINE_TYPE', 'COAL_METAL_IND', 'PRIMARY_OR_MILL']\n",
    "numerical_features = ['VIOLATOR_VIOLATION_CNT', 'VIOLATOR_INSPECTION_DAY_CNT', 'YEAR_OCCUR']\n",
    "target = ['SIG_SUB']\n",
    "\n",
    "X = train_undersampled[categorical_features + numerical_features].to_numpy()\n",
    "y = train_undersampled[target].to_numpy()\n",
    "\n",
    "categorical_indices = list(range(len(categorical_features)))\n",
    "\n",
    "smotenc_sampler = SMOTENC(random_state=0,\n",
    "                          categorical_features=categorical_indices,\n",
    "                          sampling_strategy={'Y': n_sig_target, 'N': n_non_sig_target})\n",
    "\n",
    "print('Performing SMOTENC')\n",
    "X_res, y_res = smotenc_sampler.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res = pd.DataFrame(X_res, columns=categorical_features + numerical_features)\n",
    "train_res['SIG_SUB'] = y_res\n",
    "train_res.to_csv('data/after_2010_train_smote_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Full Train Data:\n",
      "S&S: 237324\n",
      "Non-S&S: 786282\n",
      "Ratio Non-S&S / S&S:  3.313\n",
      "\n",
      "SMOTE Resampled Full Train Data:\n",
      "S&S: 511803\n",
      "Non-S&S: 511803\n",
      "Ratio Non-S&S / S&S:  1.000\n"
     ]
    }
   ],
   "source": [
    "# stats for resampled data vs original data\n",
    "\n",
    "original_full_train_data = pd.read_csv('data/after_2010_train_full.csv', index_col=0)\n",
    "resampled_full_train_data = pd.read_csv('data/after_2010_train_smote_full.csv', index_col=0)\n",
    "\n",
    "orig_not_sig, orig_sig = original_full_train_data['SIG_SUB'].value_counts()\n",
    "res_not_sig, res_sig = resampled_full_train_data['SIG_SUB'].value_counts()\n",
    "\n",
    "print(f'''Original Full Train Data:\n",
    "S&S: {orig_sig}\n",
    "Non-S&S: {orig_not_sig}\n",
    "Ratio Non-S&S / S&S: {orig_not_sig / orig_sig : .3f}''')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'''SMOTE Resampled Full Train Data:\n",
    "S&S: {res_sig}\n",
    "Non-S&S: {res_not_sig}\n",
    "Ratio Non-S&S / S&S: {res_not_sig / res_sig : .3f}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Samples in Hyperparam Train Dataset: 818884\n",
      "S&S samples after SMOTE: 409442\n",
      "Non-S&S samples after SMOTE: 409442\n",
      "Performing SMOTENC for hyperparameter train set\n"
     ]
    }
   ],
   "source": [
    "# SMOTE for hyperparam train dataset\n",
    "\n",
    "n_samples_hp = len(train_hp)\n",
    "n_sig_target_hp = int(n_samples_hp / 2)\n",
    "n_non_sig_target_hp = n_samples_hp - n_sig_target_hp\n",
    "print(f'''N Samples in Hyperparam Train Dataset: {n_samples_hp}\n",
    "S&S samples after SMOTE: {n_sig_target_hp}\n",
    "Non-S&S samples after SMOTE: {n_non_sig_target_hp}''')\n",
    "      \n",
    "# randomly drop neccesary samples from majority class (non-S&S)\n",
    "current_non_sig_n_hp = len(train_hp.query('SIG_SUB == \"N\"'))\n",
    "num_to_drop_hp = current_non_sig_n_hp - n_non_sig_target_hp\n",
    "drop_indices_hp = np.random.choice(train_hp.query('SIG_SUB == \"N\"').index, num_to_drop_hp, replace=False)\n",
    "train_undersampled_hp = train_hp.drop(drop_indices_hp)\n",
    "\n",
    "# oversample with SMOTE\n",
    "categorical_features = ['VIOLATOR_TYPE_CD', 'MINE_TYPE', 'COAL_METAL_IND', 'PRIMARY_OR_MILL']\n",
    "numerical_features = ['VIOLATOR_VIOLATION_CNT', 'VIOLATOR_INSPECTION_DAY_CNT', 'YEAR_OCCUR']\n",
    "target = ['SIG_SUB']\n",
    "\n",
    "X_hp = train_undersampled_hp[categorical_features + numerical_features].to_numpy()\n",
    "y_hp = train_undersampled_hp[target].to_numpy()\n",
    "\n",
    "categorical_indices = list(range(len(categorical_features)))\n",
    "\n",
    "smotenc_sampler_hp = SMOTENC(random_state=0,\n",
    "                          categorical_features=categorical_indices,\n",
    "                          sampling_strategy={'Y': n_sig_target_hp, 'N': n_non_sig_target_hp})\n",
    "\n",
    "print('Performing SMOTENC for hyperparameter train set')\n",
    "X_res_hp, y_res_hp = smotenc_sampler_hp.fit_resample(X_hp, y_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_hp = pd.DataFrame(X_res_hp, columns=categorical_features + numerical_features)\n",
    "train_res_hp['SIG_SUB'] = y_res_hp\n",
    "train_res_hp.to_csv('data/after_2010_train_smote_hp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Hyperparam Train Data:\n",
      "S&S: 189768\n",
      "Non-S&S: 629116\n",
      "Ratio Non-S&S / S&S:  3.315\n",
      "\n",
      "SMOTE Resampled Hyperparam Train Data:\n",
      "S&S: 409442\n",
      "Non-S&S: 409442\n",
      "Ratio Non-S&S / S&S:  1.000\n"
     ]
    }
   ],
   "source": [
    "# stats for resampled data vs original data (hyperparam train set)\n",
    "\n",
    "original_hp_train_data = pd.read_csv('data/after_2010_train_hp.csv', index_col=0)\n",
    "resampled_hp_train_data = pd.read_csv('data/after_2010_train_smote_hp.csv', index_col=0)\n",
    "\n",
    "orig_not_sig, orig_sig = original_hp_train_data['SIG_SUB'].value_counts()\n",
    "res_not_sig, res_sig = resampled_hp_train_data['SIG_SUB'].value_counts()\n",
    "\n",
    "print(f'''Original Hyperparam Train Data:\n",
    "S&S: {orig_sig}\n",
    "Non-S&S: {orig_not_sig}\n",
    "Ratio Non-S&S / S&S: {orig_not_sig / orig_sig : .3f}''')\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'''SMOTE Resampled Hyperparam Train Data:\n",
    "S&S: {res_sig}\n",
    "Non-S&S: {res_not_sig}\n",
    "Ratio Non-S&S / S&S: {res_not_sig / res_sig : .3f}''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
