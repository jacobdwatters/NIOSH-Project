{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobdwatters/NIOSH-Project/blob/main/Violation_edited.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "ZCCJBF_-vRvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "ShmmElpEtFrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWRkU0ZTjQ1p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn_pandas import DataFrameMapper\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn import set_config\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from joblib import dump, load\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "z1k9w52YwHDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjTPHF9qjbNw"
      },
      "outputs": [],
      "source": [
        "# Import Datasets and PreProcessing\n",
        "\n",
        "# violations = pd.read_csv (\"https://arlweb.msha.gov/OpenGovernmentData/DataSets/Violations.zip\", encoding='latin-1', compression='zip', sep='|')\n",
        "\n",
        "# violations['VIOLATOR_VIOLATION_CNT'] = violations['VIOLATOR_VIOLATION_CNT'].fillna('0')\n",
        "# violations['PROPOSED_PENALTY'] = violations['PROPOSED_PENALTY'].fillna('0')\n",
        "# violations['MINE_TYPE'] = violations['MINE_TYPE'].fillna('Facility')\n",
        "# violations['LIKELIHOOD'] = violations['LIKELIHOOD'].fillna('NoLikelihood')\n",
        "# violations['PROPOSED_PENALTY'] = violations['PROPOSED_PENALTY'].fillna('0')\n",
        "# violations['NEGLIGENCE'] = violations['NEGLIGENCE'].fillna('NONEGLIGENCE')\n",
        "# violations['NEGLIGENCE'] = violations['VIOLATION_ISSUE_TIME'].fillna('2319')\n",
        "# violations['COAL_METAL_IND'] = violations['COAL_METAL_IND'].fillna('M')\n",
        "# violations['NO_AFFECTED'] = violations['NO_AFFECTED'].fillna('0')\n",
        "# violations['INJ_ILLNESS'] = violations['INJ_ILLNESS'].fillna('NoLostDays')\n",
        "# violations['SIG_SUB'] = violations['SIG_SUB'].fillna('N')\n",
        "\n",
        "# violations['VIOLATION_OCCUR_DT'] = pd.to_datetime(violations['VIOLATION_OCCUR_DT'], format='%m/%d/%Y', exact=False)\n",
        "# violations.reset_index(inplace=True)\n",
        "# violations['day_occur'] = violations['VIOLATION_OCCUR_DT'].dt.day\n",
        "# violations['month_occur'] = violations['VIOLATION_OCCUR_DT'].dt.month\n",
        "# violations['year_occur'] = violations['VIOLATION_OCCUR_DT'].dt.year\n",
        "\n",
        "# violations['year_occur'] = violations['year_occur'].fillna('1999')\n",
        "\n",
        "# violations = violations._convert(numeric=True)\n",
        "\n",
        "violations = pd.read_csv('gdrive/My Drive/NIOSH Project/data/violations_processed.csv')\n",
        "\n",
        "# Selecting Parameters\n",
        "X = violations[['year_occur', \n",
        "          'VIOLATION_ISSUE_TIME',\n",
        "          'VIOLATOR_VIOLATION_CNT',\n",
        "          'MINE_TYPE', \n",
        "          'COAL_METAL_IND', \n",
        "          'NEGLIGENCE',\n",
        "          'LIKELIHOOD', \n",
        "          'NO_AFFECTED',\n",
        "          'INJ_ILLNESS',\n",
        "          'SIG_SUB']]\n",
        "\n",
        "y = violations['PROPOSED_PENALTY']\n",
        "\n",
        "# processed_data = pd.concat([X, y], axis=1)\n",
        "# path = '/content/gdrive/My Drive/NIOSH Project/data/violations_processed.csv'\n",
        "# with open(path, 'w', encoding='utf-8') as f:\n",
        "#   processed_data.to_csv(f)\n",
        "\n",
        "# del(processed_data)\n",
        "del(violations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bexZ16vrk3Ad"
      },
      "outputs": [],
      "source": [
        "X.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrfX_ZCkqAyW"
      },
      "outputs": [],
      "source": [
        "X.SIG_SUB.value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTApUygHsEkA"
      },
      "outputs": [],
      "source": [
        "X.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkMuX7itjpg9"
      },
      "outputs": [],
      "source": [
        "# Define which columns should be encoded vs scaled\n",
        "columns_to_encode = ['MINE_TYPE','COAL_METAL_IND','LIKELIHOOD','INJ_ILLNESS','SIG_SUB']\n",
        "columns_to_scale  = ['year_occur', 'VIOLATION_ISSUE_TIME', 'NEGLIGENCE', 'VIOLATOR_VIOLATION_CNT','NO_AFFECTED']\n",
        "\n",
        "# Instantiate encoder/scaler\n",
        "scaler = StandardScaler()\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Scale and Encode Separate Columns\n",
        "scaled_columns  = scaler.fit_transform(X[columns_to_scale])\n",
        "encoded_columns = ohe.fit_transform(X[columns_to_encode])\n",
        "\n",
        "# Concatenate (Column-Bind) Processed Columns Back Together\n",
        "X_pre = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
        "np.nan_to_num(X_pre, copy=False)\n",
        "\n",
        "print(\"Features shape:\", X_pre.shape)\n",
        "\n",
        "\n",
        "# Bin the values into 5 equally sized bins.\n",
        "y_bins = pd.cut(y, 5)\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_pre = le.fit_transform(y_bins)\n",
        "\n",
        "n = len(pd.unique(y))\n",
        "print(\"No.of.unique values in y:\", n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muy375z1jsRo"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pre, y_pre, test_size = 0.25, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWTCxDYSjutN"
      },
      "outputs": [],
      "source": [
        "# Fitting classifier to the Training set\n",
        "set_config(display='diagram')\n",
        "\n",
        "model = LogisticRegression(max_iter=300000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "accuracy = model.score(X_test, y_test)\n",
        "print(f\"Accuracy of logistic regression: {accuracy:.3f}\")\n",
        "\n",
        "# Save the model\n",
        "dump(model, 'gdrive/My Drive/NIOSH Project/violation_logreg_trained.joblib') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJla7fnYjxd3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_confusion_matrix(model, X_test, y_test, ax=ax, normalize='true')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "plot_confusion_matrix(model, X_test, y_test, ax=ax)\n",
        "plt.title()"
      ],
      "metadata": {
        "id": "kkHVmazrxTZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}