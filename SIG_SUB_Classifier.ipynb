{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jacobdwatters/NIOSH-Project/blob/main/SIG_SUB_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "UGS1IvByF9zn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, roc_auc_score\n",
    "from sklearn.metrics import r2_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, balanced_accuracy_score, accuracy_score, cohen_kappa_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import lightgbm as lgb\n",
    "from skranger.ensemble import RangerForestClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import violation_common\n",
    "\n",
    "from importlib import reload\n",
    "reload(violation_common)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "import joblib\n",
    "from scipy.stats import chi2_contingency\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_full = pd.read_csv('data/after_2010_train_full.csv', index_col=0)\n",
    "test = pd.read_csv('data/after_2010_test.csv', index_col=0)\n",
    "train_hp = pd.read_csv('data/after_2010_train_hp.csv', index_col=0)\n",
    "validate_hp = pd.read_csv('data/after_2010_validate_hp.csv', index_col=0)\n",
    "train_smote_full = pd.read_csv('data/after_2010_train_smote_full.csv', index_col=0)\n",
    "train_hp_smote = pd.read_csv('data/after_2010_train_smote_hp.csv', index_col=0)\n",
    "\n",
    "categorical_cols = ['PRIMARY_OR_MILL', 'COAL_METAL_IND', 'MINE_TYPE', 'VIOLATOR_TYPE_CD']\n",
    "numerical_cols = ['VIOLATOR_INSPECTION_DAY_CNT', 'VIOLATOR_VIOLATION_CNT', 'YEAR_OCCUR']\n",
    "\n",
    "target = 'SIG_SUB'\n",
    "\n",
    "feature_ranking = [\n",
    "    'YEAR_OCCUR',\n",
    "    'VIOLATOR_VIOLATION_CNT',\n",
    "    'VIOLATOR_INSPECTION_DAY_CNT',\n",
    "    'MINE_TYPE',\n",
    "    'PRIMARY_OR_MILL',\n",
    "    'COAL_METAL_IND',\n",
    "    'VIOLATOR_TYPE_CD'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_objective(trial, data_train, data_validate, metrics, objective_metric):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    num_features = trial.suggest_int('num_features', 1, len(categorical_cols) + len(numerical_cols))\n",
    "\n",
    "    X_train, y_train, preprocessor, target_transformer = violation_common.encode_and_scale(data_train, target=target, contionous_target=False, to_keep=feature_ranking[0:num_features], categorical_cols=categorical_cols, numerical_cols=numerical_cols, preprocessor=None, target_transformer=None)\n",
    "    X_validate, y_validate, _, _ = violation_common.encode_and_scale(data_validate, target=target, to_keep=feature_ranking[0:num_features], preprocessor=preprocessor, target_transformer=target_transformer)\n",
    "\n",
    "\n",
    "    model = lgb.LGBMClassifier(**param)\n",
    "    \n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_validate)[:, 1]\n",
    "    pred_labels = model.predict(X_validate)\n",
    "\n",
    "\n",
    "    # calculate metrics\n",
    "    for metric_name, metric_func, requires_proba in metrics:\n",
    "        metric_value = None\n",
    "        if requires_proba:\n",
    "            metric_value = metric_func(y_validate, preds)\n",
    "        else:\n",
    "            metric_value = metric_func(y_validate, pred_labels)\n",
    "        trial.set_user_attr(metric_name, metric_value)\n",
    "\n",
    "    return trial.user_attrs[objective_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_objective(trial, data_train, data_validate, metrics, objective_metric):\n",
    "    num_features = trial.suggest_int('num_features', 1, len(categorical_cols) + len(numerical_cols))\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 64, 128),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_node_size\": trial.suggest_int(\"min_node_size\", 1, 5),\n",
    "        \"mtry\": trial.suggest_int(\"mtry\", 0, num_features),  # num of features\n",
    "        \"split_rule\": trial.suggest_categorical(\"split_rule\", [\"gini\", \"extratrees\"]),\n",
    "        \"sample_fraction\": trial.suggest_float(\"sample_fraction\", 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    X_train, y_train, preprocessor, target_transformer = violation_common.encode_and_scale(data_train, target=target, contionous_target=False, to_keep=feature_ranking[0:num_features], categorical_cols=categorical_cols, numerical_cols=numerical_cols, preprocessor=None, target_transformer=None)\n",
    "    X_validate, y_validate, _, _ = violation_common.encode_and_scale(data_validate, target=target, to_keep=feature_ranking[0:num_features], preprocessor=preprocessor, target_transformer=target_transformer)\n",
    "\n",
    "    model = RangerForestClassifier(**param)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_validate)[:, 1]\n",
    "    pred_labels = model.predict(X_validate)\n",
    "\n",
    "\n",
    "    # calculate metrics\n",
    "    for metric_name, metric_func, requires_proba in metrics:\n",
    "        metric_value = None\n",
    "        if requires_proba:\n",
    "            metric_value = metric_func(y_validate, preds)\n",
    "        else:\n",
    "            metric_value = metric_func(y_validate, pred_labels)\n",
    "        trial.set_user_attr(metric_name, metric_value)\n",
    "\n",
    "    return trial.user_attrs[objective_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_objective(trial, data_train, data_validate, metrics, objective_metric):\n",
    "    num_features = trial.suggest_int('num_features', 1, len(categorical_cols) + len(numerical_cols))\n",
    "    param = {\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-10, 1e10, log=True),\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"saga\"]),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 100, 1000),\n",
    "    }\n",
    "\n",
    "    X_train, y_train, preprocessor, target_transformer = violation_common.encode_and_scale(data_train, target=target, contionous_target=False, to_keep=feature_ranking[0:num_features], categorical_cols=categorical_cols, numerical_cols=numerical_cols, preprocessor=None, target_transformer=None)\n",
    "    X_validate, y_validate, _, _ = violation_common.encode_and_scale(data_validate, target=target, to_keep=feature_ranking[0:num_features], preprocessor=preprocessor, target_transformer=target_transformer)\n",
    "\n",
    "    model = LogisticRegression(**param)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_validate)[:, 1]\n",
    "    pred_labels = model.predict(X_validate)\n",
    "\n",
    "\n",
    "    # calculate metrics\n",
    "    for metric_name, metric_func, requires_proba in metrics:\n",
    "        metric_value = None\n",
    "        if requires_proba:\n",
    "            metric_value = metric_func(y_validate, preds)\n",
    "        else:\n",
    "            metric_value = metric_func(y_validate, pred_labels)\n",
    "        trial.set_user_attr(metric_name, metric_value)\n",
    "\n",
    "    return trial.user_attrs[objective_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float), torch.unsqueeze(torch.tensor(self.labels[idx], dtype=torch.float), dim=0)\n",
    "\n",
    "def nn_objective(trial, data_train, data_validate, metrics, objective_metric):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Define neural network architecture\n",
    "    num_features = trial.suggest_int('num_features', 1, len(categorical_cols) + len(numerical_cols))\n",
    "\n",
    "    X_train, y_train, preprocessor, target_transformer = violation_common.encode_and_scale(data_train, target=target, contionous_target=False, to_keep=feature_ranking[0:num_features], categorical_cols=categorical_cols, numerical_cols=numerical_cols, preprocessor=None, target_transformer=None)\n",
    "    X_validate, y_validate, _, _ = violation_common.encode_and_scale(data_validate, target=target, to_keep=feature_ranking[0:num_features], preprocessor=preprocessor, target_transformer=target_transformer)\n",
    "\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    layers = []\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            layers.append(nn.Linear(input_size, trial.suggest_int(f'n_units_l{i}', 10, 500)))\n",
    "        else:\n",
    "            layers.append(nn.Linear(trial.suggest_int(f'n_units_l{i-1}', 10, 500), \n",
    "                                    trial.suggest_int(f'n_units_l{i}', 10, 500)))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout_rate))\n",
    "    layers.append(nn.Linear(trial.suggest_int(f'n_units_l{n_layers-1}', 10, 500), 1))\n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    model = nn.Sequential(*layers).to(device)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    model_train_x, early_stopping_x, model_train_y, early_stopping_y = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Create data loaders\n",
    "    model_train_dataset = ClassifierDataset(model_train_x, model_train_y)\n",
    "    val_dataset = ClassifierDataset(X_validate, y_validate)\n",
    "    early_stopping_dataset = ClassifierDataset(early_stopping_x, early_stopping_y)\n",
    "    train_loader = DataLoader(model_train_dataset, batch_size=1024, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    early_stopping_loader = DataLoader(early_stopping_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    early_stopping_best = 0\n",
    "    early_stopping_strikes = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            features, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # early stopping\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            targets = []\n",
    "            for batch in early_stopping_loader:\n",
    "                features, labels = batch\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                preds.extend(outputs.cpu().numpy())\n",
    "                targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "        early_stop_auc = roc_auc_score(targets, preds)\n",
    "        print(f'Early stopping auc: {early_stop_auc}')\n",
    "        \n",
    "        if early_stop_auc > early_stopping_best + 0.01:\n",
    "            early_stopping_best = early_stop_auc\n",
    "            early_stopping_strikes = 0\n",
    "        else:\n",
    "            if early_stop_auc > early_stopping_best:\n",
    "                early_stopping_best = early_stop_auc\n",
    "            early_stopping_strikes += 1\n",
    "            if early_stopping_strikes == 2:\n",
    "                break\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            features, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "            targets.extend(labels.cpu().numpy())\n",
    "\n",
    "    pred_labels = np.array(preds) > 0.5\n",
    "        \n",
    "    # calculate metrics\n",
    "    for metric_name, metric_func, requires_proba in metrics:\n",
    "        metric_value = None\n",
    "        if requires_proba:\n",
    "            metric_value = metric_func(y_validate, preds)\n",
    "        else:\n",
    "            metric_value = metric_func(y_validate, pred_labels)\n",
    "        trial.set_user_attr(metric_name, metric_value)\n",
    "\n",
    "    return trial.user_attrs[objective_metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_types = ['non_smote', 'smote']\n",
    "#model_types = [('lightgbm', lgb_objective)]\n",
    "#model_types = [('random_forest', rf_objective)]\n",
    "#model_types = [('logistic_regression', logistic_objective)]\n",
    "#model_types = [('neural_network', nn_objective)]\n",
    "\n",
    "# model types is a list of tuples of model names and objective functions and number of trials\n",
    "model_types = [('lightgbm', lgb_objective, 10), ('random_forest', rf_objective, 10), ('logistic_regression', logistic_objective, 10), ('neural_network', nn_objective, 5)]\n",
    "\n",
    "# list of tuples of metric names and functions along with whether they require a probability prediction\n",
    "metrics = [('roc_auc_score', roc_auc_score, True),\n",
    "           ('accuracy_score', accuracy_score, False),\n",
    "           ('balanced_accuracy_score', balanced_accuracy_score, False),\n",
    "           ('f1_score', f1_score, False),\n",
    "           ('precision_score', precision_score, False),\n",
    "           ('recall_score', recall_score, False),\n",
    "           ('cohen_kappa_score', cohen_kappa_score, False),\n",
    "           ('confusion_matrix', confusion_matrix, False)]\n",
    "\n",
    "# results[dataset_type][model_name] = study\n",
    "hp_validation_results = {dataset_type: {model_name[0]: None for model_name in model_types} for dataset_type in dataset_types}\n",
    "\n",
    "for dataset_type in dataset_types:\n",
    "    for model_name, objective, n_trials in model_types:\n",
    "        print(f'SMOTE: {dataset_type}, Model: {model_name}')\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        trial_train_data = train_hp_smote if dataset_type == 'smote' else train_hp\n",
    "        study.optimize(lambda trial: objective(trial,\n",
    "                                               data_train=trial_train_data,\n",
    "                                               data_validate=validate_hp,\n",
    "                                               metrics=metrics,\n",
    "                                               objective_metric='roc_auc_score'),\n",
    "                       n_trials=n_trials)\n",
    "\n",
    "        print(\"Best trial:\")\n",
    "        trial = study.best_trial\n",
    "\n",
    "        print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))\n",
    "            \n",
    "        hp_validation_results[dataset_type][model_name] = study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: non_smote, Model: lightgbm\n",
      "Best hyperparameters:\n",
      "{'bagging_fraction': 0.578853457712694,\n",
      " 'bagging_freq': 2,\n",
      " 'feature_fraction': 0.9432804076931858,\n",
      " 'lambda_l1': 0.00022058704416932193,\n",
      " 'lambda_l2': 0.8186572930303238,\n",
      " 'min_child_samples': 31,\n",
      " 'num_features': 5,\n",
      " 'num_leaves': 171}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.767914537763406,\n",
      " 'balanced_accuracy_score': 0.502116592144414,\n",
      " 'cohen_kappa_score': 0.006463502879039296,\n",
      " 'confusion_matrix': array([[156939,    227],\n",
      "       [ 47286,    270]]),\n",
      " 'f1_score': 0.011237591825692464,\n",
      " 'precision_score': 0.5432595573440644,\n",
      " 'recall_score': 0.005677517032551098,\n",
      " 'roc_auc_score': 0.5914903380005341}\n",
      "\n",
      "SMOTE: non_smote, Model: random_forest\n",
      "Best hyperparameters:\n",
      "{'max_depth': 9,\n",
      " 'min_node_size': 2,\n",
      " 'mtry': 5,\n",
      " 'n_estimators': 108,\n",
      " 'num_features': 5,\n",
      " 'sample_fraction': 0.7689132514325179,\n",
      " 'split_rule': 'gini'}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.7677777669229492,\n",
      " 'balanced_accuracy_score': 0.5003630207881562,\n",
      " 'cohen_kappa_score': 0.001113880382245136,\n",
      " 'confusion_matrix': array([[157138,     28],\n",
      "       [ 47513,     43]]),\n",
      " 'f1_score': 0.001805698448359124,\n",
      " 'precision_score': 0.6056338028169014,\n",
      " 'recall_score': 0.0009041971570359156,\n",
      " 'roc_auc_score': 0.5818550919485939}\n",
      "\n",
      "SMOTE: non_smote, Model: logistic_regression\n",
      "Best hyperparameters:\n",
      "{'C': 0.0007634595183021707,\n",
      " 'max_iter': 822,\n",
      " 'num_features': 7,\n",
      " 'penalty': 'l1',\n",
      " 'solver': 'liblinear'}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.7677044968298473,\n",
      " 'balanced_accuracy_score': 0.5,\n",
      " 'cohen_kappa_score': 0.0,\n",
      " 'confusion_matrix': array([[157166,      0],\n",
      "       [ 47556,      0]]),\n",
      " 'f1_score': 0.0,\n",
      " 'precision_score': 0.0,\n",
      " 'recall_score': 0.0,\n",
      " 'roc_auc_score': 0.5660161968084827}\n",
      "\n",
      "SMOTE: non_smote, Model: neural_network\n",
      "Best hyperparameters:\n",
      "{'dropout_rate': 0.20382953282240984,\n",
      " 'lr': 0.00027767918848990605,\n",
      " 'n_layers': 1,\n",
      " 'n_units_l0': 445,\n",
      " 'num_features': 4}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.7677044968298473,\n",
      " 'balanced_accuracy_score': 0.5,\n",
      " 'cohen_kappa_score': 0.0,\n",
      " 'confusion_matrix': array([[157166,      0],\n",
      "       [ 47556,      0]]),\n",
      " 'f1_score': 0.0,\n",
      " 'precision_score': 0.0,\n",
      " 'recall_score': 0.0,\n",
      " 'roc_auc_score': 0.5624668571279615}\n",
      "\n",
      "SMOTE: smote, Model: lightgbm\n",
      "Best hyperparameters:\n",
      "{'bagging_fraction': 0.4941272318108069,\n",
      " 'bagging_freq': 6,\n",
      " 'feature_fraction': 0.5895504101884543,\n",
      " 'lambda_l1': 8.622375779406829,\n",
      " 'lambda_l2': 5.7636539404317885e-05,\n",
      " 'min_child_samples': 96,\n",
      " 'num_features': 1,\n",
      " 'num_leaves': 39}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.23229550317015268,\n",
      " 'balanced_accuracy_score': 0.5,\n",
      " 'cohen_kappa_score': 0.0,\n",
      " 'confusion_matrix': array([[     0, 157166],\n",
      "       [     0,  47556]]),\n",
      " 'f1_score': 0.37701266063628214,\n",
      " 'precision_score': 0.23229550317015268,\n",
      " 'recall_score': 1.0,\n",
      " 'roc_auc_score': 0.5133654149152613}\n",
      "\n",
      "SMOTE: smote, Model: random_forest\n",
      "Best hyperparameters:\n",
      "{'max_depth': 7,\n",
      " 'min_node_size': 5,\n",
      " 'mtry': 0,\n",
      " 'n_estimators': 72,\n",
      " 'num_features': 6,\n",
      " 'sample_fraction': 0.5365750764993555,\n",
      " 'split_rule': 'extratrees'}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.5101650042496654,\n",
      " 'balanced_accuracy_score': 0.5474261449958379,\n",
      " 'cohen_kappa_score': 0.06460385996500773,\n",
      " 'confusion_matrix': array([[75099, 82067],\n",
      "       [18213, 29343]]),\n",
      " 'f1_score': 0.3691732823371035,\n",
      " 'precision_score': 0.2633785118032493,\n",
      " 'recall_score': 0.6170199343931365,\n",
      " 'roc_auc_score': 0.5658739663424627}\n",
      "\n",
      "SMOTE: smote, Model: logistic_regression\n",
      "Best hyperparameters:\n",
      "{'C': 53682.47220973401,\n",
      " 'max_iter': 530,\n",
      " 'num_features': 7,\n",
      " 'penalty': 'l1',\n",
      " 'solver': 'liblinear'}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.5283555260304218,\n",
      " 'balanced_accuracy_score': 0.5471600841938661,\n",
      " 'cohen_kappa_score': 0.06657828443248359,\n",
      " 'confusion_matrix': array([[80475, 76691],\n",
      "       [19865, 27691]]),\n",
      " 'f1_score': 0.3645039423975569,\n",
      " 'precision_score': 0.2652852024295377,\n",
      " 'recall_score': 0.5822819412902683,\n",
      " 'roc_auc_score': 0.566081198332496}\n",
      "\n",
      "SMOTE: smote, Model: neural_network\n",
      "Best hyperparameters:\n",
      "{'dropout_rate': 0.19441622003444148,\n",
      " 'lr': 0.005521658585105953,\n",
      " 'n_layers': 2,\n",
      " 'n_units_l0': 50,\n",
      " 'n_units_l1': 349,\n",
      " 'num_features': 6}\n",
      "Metrics:\n",
      "{'accuracy_score': 0.4912808589208781,\n",
      " 'balanced_accuracy_score': 0.5483696700460194,\n",
      " 'cohen_kappa_score': 0.06351697879152496,\n",
      " 'confusion_matrix': array([[69427, 87739],\n",
      "       [16407, 31149]]),\n",
      " 'f1_score': 0.3742880488332412,\n",
      " 'precision_score': 0.2620028934795774,\n",
      " 'recall_score': 0.654996214988645,\n",
      " 'roc_auc_score': 0.5692777423513127}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_type in dataset_types:\n",
    "    for model_name, objective, _ in model_types:\n",
    "        print(f'SMOTE: {dataset_type}, Model: {model_name}')\n",
    "        print(\"Best hyperparameters:\")\n",
    "        pprint(hp_validation_results[dataset_type][model_name].best_params)\n",
    "        print(\"Metrics:\")\n",
    "        pprint(hp_validation_results[dataset_type][model_name].best_trial.user_attrs)\n",
    "        print()\n",
    "\n",
    "# Save results with pickle\n",
    "with open('data/hp_validation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(hp_validation_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lambda_l1': 1.2683782903367314e-07, 'lambda_l2': 0.0008330722610290878, 'num_leaves': 187, 'feature_fraction': 0.8097281553546072, 'bagging_fraction': 0.6896292970533484, 'bagging_freq': 5, 'min_child_samples': 100, 'num_features': 6}\n"
     ]
    }
   ],
   "source": [
    "with open('data/hp_validation_results.pkl', 'rb') as f:\n",
    "    hp_validation_results = pickle.load(f)\n",
    "    print(hp_validation_results['non_smote']['lightgbm'].best_params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOy6IAzskCTKnJ5dw5sqpaV",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
