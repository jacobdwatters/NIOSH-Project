{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMcIpnGEt//X5Qs/gtTHFWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobdwatters/NIOSH-Project/blob/main/KerasNeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setups"
      ],
      "metadata": {
        "id": "kksCVOwmWIyk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "1QV40HghV7bg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDHS2sE2WBmY",
        "outputId": "e799bfda-369a-4980-8616-a4d4ee43b1a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Process Data"
      ],
      "metadata": {
        "id": "qsJjYUJgWOtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_after_2010 = '/content/gdrive/My Drive/NIOSH Project/data/violations_processed_after_2010.csv'\n",
        "violation_data = pd.read_csv(path_after_2010)"
      ],
      "metadata": {
        "id": "7U5StloDWL2d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURES = ['MINE_TYPE', 'COAL_METAL_IND', 'SIG_SUB', 'LIKELIHOOD', \n",
        "            'INJ_ILLNESS', 'NO_AFFECTED', 'NEGLIGENCE', 'VIOLATOR_VIOLATION_CNT',\n",
        "            'VIOLATOR_INSPECTION_DAY_CNT']\n",
        "TARGETS = ['PROPOSED_PENALTY']\n",
        "\n",
        "X = violation_data[FEATURES]\n",
        "y = violation_data[TARGETS]"
      ],
      "metadata": {
        "id": "ZWdMdDejWRNE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define which columns should be encoded vs scaled\n",
        "columns_to_encode = ['MINE_TYPE', 'COAL_METAL_IND', 'LIKELIHOOD', 'INJ_ILLNESS', 'SIG_SUB', 'NEGLIGENCE']\n",
        "columns_to_scale  = ['VIOLATOR_VIOLATION_CNT', 'NO_AFFECTED', 'VIOLATOR_INSPECTION_DAY_CNT']\n",
        "\n",
        "# Instantiate encoder/scaler\n",
        "scaler = StandardScaler()\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Scale and Encode Separate Columns\n",
        "scaled_columns  = scaler.fit_transform(X[columns_to_scale])\n",
        "encoded_columns = ohe.fit_transform(X[columns_to_encode])\n",
        "\n",
        "# Concatenate (Column-Bind) Processed Columns Back Together\n",
        "X_pre = np.concatenate([scaled_columns, encoded_columns], axis=1)\n",
        "np.nan_to_num(X_pre, copy=False)\n",
        "\n",
        "print('Features shape:', X_pre.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVgtHrMyWTND",
        "outputId": "ca812769-8732-4091-91f4-a97873668a07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (1429135, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_pre, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_train shape:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di0OVsjxWUix",
        "outputId": "89baf242-daa4-4c32-d067-3fea97ea42dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1071851, 24)\n",
            "X_test shape: (357284, 24)\n",
            "y_train shape: (1071851, 1)\n",
            "y_train shape: (357284, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network Model"
      ],
      "metadata": {
        "id": "y1ufEC5wWgyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 85:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr*np.exp(-0.05)"
      ],
      "metadata": {
        "id": "hyuGxyqFgRVi"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2**14\n",
        "epochs = 150\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.Input(shape = (len(X_train[0]), ) ))\n",
        "model.add(layers.Dense(32, activation=\"relu\"))\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(16, activation=\"relu\"))\n",
        "model.add(layers.Dense(8, activation=\"relu\"))\n",
        "model.add(layers.Dense(4, activation=\"relu\"))\n",
        "model.add(layers.Dense(2, activation=\"relu\"))\n",
        "model.add(layers.Dense(1, activation=\"linear\"))\n",
        "\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss=\"mse\", optimizer=opt)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, \n",
        "                    callbacks=[callback], validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azr8bSFRWikn",
        "outputId": "14fcb5c6-820b-4e82-ffe6-aa56f322b1db"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "66/66 [==============================] - 1s 8ms/step - loss: 12178146.0000 - val_loss: 10371828.0000 - lr: 0.0100\n",
            "Epoch 2/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 9835179.0000 - val_loss: 8010073.0000 - lr: 0.0100\n",
            "Epoch 3/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 7282250.0000 - val_loss: 6257692.5000 - lr: 0.0100\n",
            "Epoch 4/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6545901.0000 - val_loss: 6139356.0000 - lr: 0.0100\n",
            "Epoch 5/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6560589.5000 - val_loss: 6208180.5000 - lr: 0.0100\n",
            "Epoch 6/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6448579.5000 - val_loss: 6088908.5000 - lr: 0.0100\n",
            "Epoch 7/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6335752.5000 - val_loss: 6031622.0000 - lr: 0.0100\n",
            "Epoch 8/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6320151.5000 - val_loss: 6167032.0000 - lr: 0.0100\n",
            "Epoch 9/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 6247939.5000 - val_loss: 6358267.0000 - lr: 0.0100\n",
            "Epoch 10/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 6365750.0000 - val_loss: 6083383.5000 - lr: 0.0100\n",
            "Epoch 11/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 6232468.5000 - val_loss: 5932490.5000 - lr: 0.0100\n",
            "Epoch 12/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 6109679.5000 - val_loss: 5886545.0000 - lr: 0.0100\n",
            "Epoch 13/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5941920.0000 - val_loss: 5606680.0000 - lr: 0.0100\n",
            "Epoch 14/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5831675.5000 - val_loss: 5510038.0000 - lr: 0.0100\n",
            "Epoch 15/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5824702.0000 - val_loss: 5512454.5000 - lr: 0.0100\n",
            "Epoch 16/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5690167.0000 - val_loss: 5458543.0000 - lr: 0.0100\n",
            "Epoch 17/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5662425.0000 - val_loss: 5422460.5000 - lr: 0.0100\n",
            "Epoch 18/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5642193.5000 - val_loss: 5397315.5000 - lr: 0.0100\n",
            "Epoch 19/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5601761.5000 - val_loss: 5401844.0000 - lr: 0.0100\n",
            "Epoch 20/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5605902.5000 - val_loss: 5397453.0000 - lr: 0.0100\n",
            "Epoch 21/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5561351.0000 - val_loss: 5362731.5000 - lr: 0.0100\n",
            "Epoch 22/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5562961.0000 - val_loss: 5402650.0000 - lr: 0.0100\n",
            "Epoch 23/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5584278.0000 - val_loss: 5344565.5000 - lr: 0.0100\n",
            "Epoch 24/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5525344.0000 - val_loss: 5368788.0000 - lr: 0.0100\n",
            "Epoch 25/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5534570.5000 - val_loss: 5337273.0000 - lr: 0.0100\n",
            "Epoch 26/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5475008.5000 - val_loss: 5478119.5000 - lr: 0.0100\n",
            "Epoch 27/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5472232.5000 - val_loss: 5273587.5000 - lr: 0.0100\n",
            "Epoch 28/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5435669.0000 - val_loss: 5267331.5000 - lr: 0.0100\n",
            "Epoch 29/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5811929.5000 - val_loss: 5270877.5000 - lr: 0.0100\n",
            "Epoch 30/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5424310.5000 - val_loss: 5217754.5000 - lr: 0.0100\n",
            "Epoch 31/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5385110.5000 - val_loss: 5203135.0000 - lr: 0.0100\n",
            "Epoch 32/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5356071.0000 - val_loss: 5231497.5000 - lr: 0.0100\n",
            "Epoch 33/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5342773.5000 - val_loss: 5156857.5000 - lr: 0.0100\n",
            "Epoch 34/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5305639.0000 - val_loss: 5156778.0000 - lr: 0.0100\n",
            "Epoch 35/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5288728.5000 - val_loss: 5358969.5000 - lr: 0.0100\n",
            "Epoch 36/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5316590.5000 - val_loss: 5108311.5000 - lr: 0.0100\n",
            "Epoch 37/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5284466.0000 - val_loss: 5181105.5000 - lr: 0.0100\n",
            "Epoch 38/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5260381.5000 - val_loss: 5159570.5000 - lr: 0.0100\n",
            "Epoch 39/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5242694.0000 - val_loss: 5139330.0000 - lr: 0.0100\n",
            "Epoch 40/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5240214.0000 - val_loss: 5096710.5000 - lr: 0.0100\n",
            "Epoch 41/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5245498.0000 - val_loss: 5137640.0000 - lr: 0.0100\n",
            "Epoch 42/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5247326.5000 - val_loss: 5100395.0000 - lr: 0.0100\n",
            "Epoch 43/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5227709.0000 - val_loss: 5196657.5000 - lr: 0.0100\n",
            "Epoch 44/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5227831.5000 - val_loss: 5126295.0000 - lr: 0.0100\n",
            "Epoch 45/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5234321.5000 - val_loss: 5062452.5000 - lr: 0.0100\n",
            "Epoch 46/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5247769.0000 - val_loss: 5114538.5000 - lr: 0.0100\n",
            "Epoch 47/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5230718.0000 - val_loss: 5135450.0000 - lr: 0.0100\n",
            "Epoch 48/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5202875.0000 - val_loss: 5107032.5000 - lr: 0.0100\n",
            "Epoch 49/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5212215.0000 - val_loss: 5095928.0000 - lr: 0.0100\n",
            "Epoch 50/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5217865.0000 - val_loss: 5050176.5000 - lr: 0.0100\n",
            "Epoch 51/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5190564.0000 - val_loss: 5050866.5000 - lr: 0.0100\n",
            "Epoch 52/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5180404.0000 - val_loss: 5057302.0000 - lr: 0.0100\n",
            "Epoch 53/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5169746.0000 - val_loss: 5008251.0000 - lr: 0.0100\n",
            "Epoch 54/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5182088.0000 - val_loss: 5040591.5000 - lr: 0.0100\n",
            "Epoch 55/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5172098.5000 - val_loss: 5014345.0000 - lr: 0.0100\n",
            "Epoch 56/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5171631.5000 - val_loss: 5186475.0000 - lr: 0.0100\n",
            "Epoch 57/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5184059.0000 - val_loss: 5017613.0000 - lr: 0.0100\n",
            "Epoch 58/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5139714.5000 - val_loss: 5003619.0000 - lr: 0.0100\n",
            "Epoch 59/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5130795.5000 - val_loss: 5068070.5000 - lr: 0.0100\n",
            "Epoch 60/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5138667.5000 - val_loss: 4968185.5000 - lr: 0.0100\n",
            "Epoch 61/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5105682.0000 - val_loss: 5047952.0000 - lr: 0.0100\n",
            "Epoch 62/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5108568.0000 - val_loss: 4970564.0000 - lr: 0.0100\n",
            "Epoch 63/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5101987.5000 - val_loss: 4937937.0000 - lr: 0.0100\n",
            "Epoch 64/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5100669.5000 - val_loss: 4994444.5000 - lr: 0.0100\n",
            "Epoch 65/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5084753.0000 - val_loss: 4969353.0000 - lr: 0.0100\n",
            "Epoch 66/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5085771.5000 - val_loss: 4968074.5000 - lr: 0.0100\n",
            "Epoch 67/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5053375.0000 - val_loss: 5127604.0000 - lr: 0.0100\n",
            "Epoch 68/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5072057.0000 - val_loss: 5013735.5000 - lr: 0.0100\n",
            "Epoch 69/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5081428.0000 - val_loss: 4965493.0000 - lr: 0.0100\n",
            "Epoch 70/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5055293.0000 - val_loss: 5007901.0000 - lr: 0.0100\n",
            "Epoch 71/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5049318.5000 - val_loss: 5030808.5000 - lr: 0.0100\n",
            "Epoch 72/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5034034.0000 - val_loss: 5005126.0000 - lr: 0.0100\n",
            "Epoch 73/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5046473.5000 - val_loss: 4960425.5000 - lr: 0.0100\n",
            "Epoch 74/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5029478.5000 - val_loss: 4961838.5000 - lr: 0.0100\n",
            "Epoch 75/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5028804.5000 - val_loss: 4912818.5000 - lr: 0.0100\n",
            "Epoch 76/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5020139.0000 - val_loss: 4945560.5000 - lr: 0.0100\n",
            "Epoch 77/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5023578.5000 - val_loss: 5122572.5000 - lr: 0.0100\n",
            "Epoch 78/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5032879.0000 - val_loss: 4884801.0000 - lr: 0.0100\n",
            "Epoch 79/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5039569.5000 - val_loss: 4952358.0000 - lr: 0.0100\n",
            "Epoch 80/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 5009936.5000 - val_loss: 4924916.0000 - lr: 0.0100\n",
            "Epoch 81/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4993498.0000 - val_loss: 4935152.5000 - lr: 0.0100\n",
            "Epoch 82/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4989212.5000 - val_loss: 4859939.0000 - lr: 0.0100\n",
            "Epoch 83/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 5007940.0000 - val_loss: 4871583.5000 - lr: 0.0100\n",
            "Epoch 84/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4975920.0000 - val_loss: 4869662.0000 - lr: 0.0100\n",
            "Epoch 85/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4971497.5000 - val_loss: 4824556.5000 - lr: 0.0100\n",
            "Epoch 86/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4991411.5000 - val_loss: 4842888.0000 - lr: 0.0095\n",
            "Epoch 87/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4990567.5000 - val_loss: 4846040.0000 - lr: 0.0090\n",
            "Epoch 88/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4994480.0000 - val_loss: 4844953.0000 - lr: 0.0086\n",
            "Epoch 89/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4967643.0000 - val_loss: 4871680.5000 - lr: 0.0082\n",
            "Epoch 90/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4949764.5000 - val_loss: 4823066.0000 - lr: 0.0078\n",
            "Epoch 91/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4942734.5000 - val_loss: 4810319.5000 - lr: 0.0074\n",
            "Epoch 92/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4940701.0000 - val_loss: 4825375.0000 - lr: 0.0070\n",
            "Epoch 93/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4944398.0000 - val_loss: 4828925.5000 - lr: 0.0067\n",
            "Epoch 94/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4915889.0000 - val_loss: 4810873.5000 - lr: 0.0064\n",
            "Epoch 95/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4920411.0000 - val_loss: 4851593.5000 - lr: 0.0061\n",
            "Epoch 96/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4918346.0000 - val_loss: 4833946.5000 - lr: 0.0058\n",
            "Epoch 97/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4898219.5000 - val_loss: 4795251.0000 - lr: 0.0055\n",
            "Epoch 98/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4892683.5000 - val_loss: 4825115.5000 - lr: 0.0052\n",
            "Epoch 99/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4887682.5000 - val_loss: 4854624.5000 - lr: 0.0050\n",
            "Epoch 100/150\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 4889915.5000 - val_loss: 4821973.5000 - lr: 0.0047\n",
            "Epoch 101/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4881271.0000 - val_loss: 4850326.0000 - lr: 0.0045\n",
            "Epoch 102/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4879141.0000 - val_loss: 4846284.5000 - lr: 0.0043\n",
            "Epoch 103/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4869996.5000 - val_loss: 4829312.5000 - lr: 0.0041\n",
            "Epoch 104/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4879605.0000 - val_loss: 4875511.5000 - lr: 0.0039\n",
            "Epoch 105/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4872845.0000 - val_loss: 4769831.5000 - lr: 0.0037\n",
            "Epoch 106/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4866837.5000 - val_loss: 4838813.5000 - lr: 0.0035\n",
            "Epoch 107/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4853375.0000 - val_loss: 4844622.5000 - lr: 0.0033\n",
            "Epoch 108/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4853116.5000 - val_loss: 4814071.5000 - lr: 0.0032\n",
            "Epoch 109/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4853427.0000 - val_loss: 4872432.5000 - lr: 0.0030\n",
            "Epoch 110/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4860504.5000 - val_loss: 4818281.0000 - lr: 0.0029\n",
            "Epoch 111/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4851257.0000 - val_loss: 4821707.0000 - lr: 0.0027\n",
            "Epoch 112/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4840556.5000 - val_loss: 4834039.5000 - lr: 0.0026\n",
            "Epoch 113/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4853988.5000 - val_loss: 4848159.0000 - lr: 0.0025\n",
            "Epoch 114/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4839686.0000 - val_loss: 4807127.0000 - lr: 0.0023\n",
            "Epoch 115/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4848837.0000 - val_loss: 4817312.0000 - lr: 0.0022\n",
            "Epoch 116/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4837400.5000 - val_loss: 4804624.0000 - lr: 0.0021\n",
            "Epoch 117/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4829813.0000 - val_loss: 4798732.0000 - lr: 0.0020\n",
            "Epoch 118/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4824249.0000 - val_loss: 4787912.0000 - lr: 0.0019\n",
            "Epoch 119/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4827443.5000 - val_loss: 4778143.5000 - lr: 0.0018\n",
            "Epoch 120/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4823017.5000 - val_loss: 4804760.5000 - lr: 0.0017\n",
            "Epoch 121/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4818694.0000 - val_loss: 4810699.0000 - lr: 0.0017\n",
            "Epoch 122/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4821033.0000 - val_loss: 4799725.5000 - lr: 0.0016\n",
            "Epoch 123/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4821810.0000 - val_loss: 4831391.5000 - lr: 0.0015\n",
            "Epoch 124/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4816450.5000 - val_loss: 4815575.0000 - lr: 0.0014\n",
            "Epoch 125/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4820335.5000 - val_loss: 4781661.0000 - lr: 0.0014\n",
            "Epoch 126/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4816783.5000 - val_loss: 4804888.5000 - lr: 0.0013\n",
            "Epoch 127/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4810749.0000 - val_loss: 4790886.0000 - lr: 0.0012\n",
            "Epoch 128/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4814917.0000 - val_loss: 4782866.0000 - lr: 0.0012\n",
            "Epoch 129/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4813127.5000 - val_loss: 4808931.0000 - lr: 0.0011\n",
            "Epoch 130/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4808661.5000 - val_loss: 4790615.0000 - lr: 0.0011\n",
            "Epoch 131/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4805759.5000 - val_loss: 4792905.5000 - lr: 0.0010\n",
            "Epoch 132/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4810836.0000 - val_loss: 4800764.5000 - lr: 9.5369e-04\n",
            "Epoch 133/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4804411.5000 - val_loss: 4793422.0000 - lr: 9.0718e-04\n",
            "Epoch 134/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4801825.0000 - val_loss: 4797338.0000 - lr: 8.6294e-04\n",
            "Epoch 135/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4805350.0000 - val_loss: 4810172.5000 - lr: 8.2085e-04\n",
            "Epoch 136/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4802496.5000 - val_loss: 4792556.0000 - lr: 7.8082e-04\n",
            "Epoch 137/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4802627.5000 - val_loss: 4801290.5000 - lr: 7.4274e-04\n",
            "Epoch 138/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4802825.0000 - val_loss: 4800866.0000 - lr: 7.0651e-04\n",
            "Epoch 139/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4799712.5000 - val_loss: 4808279.5000 - lr: 6.7206e-04\n",
            "Epoch 140/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4797215.0000 - val_loss: 4783845.5000 - lr: 6.3928e-04\n",
            "Epoch 141/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4797305.5000 - val_loss: 4806228.0000 - lr: 6.0810e-04\n",
            "Epoch 142/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4798245.0000 - val_loss: 4797584.0000 - lr: 5.7844e-04\n",
            "Epoch 143/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4797832.5000 - val_loss: 4806627.5000 - lr: 5.5023e-04\n",
            "Epoch 144/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4796518.0000 - val_loss: 4793658.0000 - lr: 5.2340e-04\n",
            "Epoch 145/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4794686.5000 - val_loss: 4809944.5000 - lr: 4.9787e-04\n",
            "Epoch 146/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4795705.0000 - val_loss: 4805741.0000 - lr: 4.7359e-04\n",
            "Epoch 147/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4794728.5000 - val_loss: 4800365.0000 - lr: 4.5049e-04\n",
            "Epoch 148/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4793862.0000 - val_loss: 4795860.0000 - lr: 4.2852e-04\n",
            "Epoch 149/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4794318.5000 - val_loss: 4818943.5000 - lr: 4.0762e-04\n",
            "Epoch 150/150\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 4791636.0000 - val_loss: 4797172.5000 - lr: 3.8774e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print('r2 = %.3f' % r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgXhtv4UZaw3",
        "outputId": "8004e0e5-5768-46f9-f304-24d81fa91550"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11166/11166 [==============================] - 14s 1ms/step\n",
            "r2 = 0.573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "34dgk5DaYseU",
        "outputId": "e9618d41-c3d7-4f6e-8621-f9634ba27de1"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc5bn38e+9RSutuiW5yg1jcAMM2IADJKYZU2Ja6HBCDgRyXkgFTuCEkISTBHKlQAolDiG0BEIJxAmmV3NoNsYY924sV1m2et3d+/3jGclrWe5areS5P9fly9qZ2ZlHY2t/euqIqmKMMca/AukugDHGmPSyIDDGGJ+zIDDGGJ+zIDDGGJ+zIDDGGJ+zIDDGGJ+zIDBmD4nIwyLy0z08dpWInLq/5zGmK1gQGGOMz1kQGGOMz1kQmAOK1yRzs4jMFZE6EfmziPQRkRdFpEZEXhORwqTjp4jIfBGpFJG3RGRk0r4jRWS2976/A5ntrnW2iMzx3vueiBy+j2X+uogsE5EtIjJNRPp720VE7haRTSJSLSKficgYb9+ZIrLAK9taEblpn26YMVgQmAPTBcBpwCHAl4EXgf8BSnD/578FICKHAE8A3/H2TQf+JSIZIpIBPA88BvQCnvbOi/feI4GHgOuAIuCPwDQRiexNQUXkZOBO4CKgH7AaeNLbPQn4ovd95HvHVHj7/gxcp6q5wBjgjb25rjHJemQQiMhD3m9J8/bg2Lu939rmiMgSEansijKatPq9qm5U1bXADOBDVf1EVRuB54AjveMuBl5Q1VdVtQX4FZAFfAE4DggD96hqi6o+A8xMusa1wB9V9UNVjavqI0CT9769cTnwkKrOVtUm4FZggogMAVqAXGAEIKq6UFXXe+9rAUaJSJ6qblXV2Xt5XWPa9MggAB4GJu/Jgar6XVUdq6pjgd8D/0hlwUy3sDHp64YOXud4X/fH/QYOgKomgDXAAG/fWt1+VcbVSV8PBm70moUqvV8wBnrv2xvty1CL+61/gKq+AfwBuBfYJCJTRSTPO/QC4ExgtYi8LSIT9vK6xrTpkUGgqu8AW5K3icgwEXlJRD4WkRkiMqKDt16KawowBmAd7gMdcG3yuA/ztcB6YIC3rdWgpK/XAD9T1YKkP1FV3dv/X+3LkI1raloLoKq/U9WjgVG4JqKbve0zVfUcoDeuCeupvbyuMW16ZBDsxFTgm94PzU3Afck7RWQwMBRrSzXbPAWcJSKniEgYuBHXvPMe8D4QA74lImEROR84Jum9fwK+ISLHep262SJylojk7mUZngC+JiJjvf6Fn+OaslaJyHjv/GGgDmgEEl4fxuUiku81aVUDif24D8bnDoggEJEcXLvu0yIyB9dx16/dYZcAz6hqvKvLZ7onVV0MXIFrMtyM61j+sqo2q2ozcD5wFa72eTFJzYqqOgv4Oq7pZiuwzDt2b8vwGvBD4FlcLWQY7v8qQB4ucLbimo8qgF96+64EVolINfANXF+DMftEeuqDabzOtH+r6hiv3XSxqrb/8E8+/hPgelV9r4uKaIwxPcIBUSNQ1WpgpYhcCG3jr49o3e/1FxTiqvvGGGOS9MggEJEncB/qh4pImYhcjasaXy0inwLzgXOS3nIJ8KT21OqPMcakUI9tGjLGGNM5emSNwBhjTOcJpbsAe6u4uFiHDBmS7mIYY0yP8vHHH29W1ZKO9vW4IBgyZAizZs1KdzGMMaZHEZHVO9tnTUPGGONzFgTGGONzFgTGGONzPa6PoCMtLS2UlZXR2NiY7qKkXGZmJqWlpYTD4XQXxRhzgDgggqCsrIzc3FyGDBnC9otFHlhUlYqKCsrKyhg6dGi6i2OMOUAcEE1DjY2NFBUVHdAhACAiFBUV+aLmY4zpOgdEEAAHfAi08sv3aYzpOgdMEOxOY0ucDVWNxOK2bLsxxiTzTRA0tcTZVNNIS6Lz11aqrKzkvvvu2/2B7Zx55plUVtojlI0x6eWbIGhtUknFIns7C4JYLLbL902fPp2CgoJOL48xxuyNlAWBiDwkIptEZN5O9l8uInNF5DMReS/5+QGpEPCa1lNQIeCWW25h+fLljB07lvHjx3PiiScyZcoURo0aBcC5557L0UcfzejRo5k6dWrb+4YMGcLmzZtZtWoVI0eO5Otf/zqjR49m0qRJNDQ0dH5BjTGmA6kcPvow7jF+j+5k/0rgS6q6VUTOwD1z+Nj9vehP/jWfBeuqd9ieUKWhOU5mOEgwsHcdrqP65/GjL4/e6f677rqLefPmMWfOHN566y3OOuss5s2b1zbE86GHHqJXr140NDQwfvx4LrjgAoqKirY7x9KlS3niiSf405/+xEUXXcSzzz7LFVdcsVflNMaYfZGyIFDVd7zHSe5sf/IjIz8ASlNVlq52zDHHbDfO/3e/+x3PPfccAGvWrGHp0qU7BMHQoUMZO3YsAEcffTSrVq3qsvIaY/ytu0wouxp4cWc7ReRa4FqAQYMG7fJEO/vNvbElzpKNNQzqFaUgmrHvJd0D2dnZbV+/9dZbvPbaa7z//vtEo1EmTpzY4TyASCTS9nUwGLSmIWNMl0l7Z7GInIQLgu/v7BhVnaqq41R1XElJh8tp71Yq+whyc3OpqanpcF9VVRWFhYVEo1EWLVrEBx980PkFMMaY/ZDWGoGIHA48CJyhqhUpvhaQmlFDRUVFHH/88YwZM4asrCz69OnTtm/y5Mk88MADjBw5kkMPPZTjjjuu069vjDH7I21BICKDgH8AV6rqkpRfz/s7FTUCgL/97W8dbo9EIrz4YsetXq39AMXFxcybt21w1U033dTp5TPGmJ1JWRCIyBPARKBYRMqAHwFhAFV9ALgdKALu835bj6nquFSVJ5DCGoExxvRkqRw1dOlu9l8DXJOq67fXukSPLTBhjDHbS3tncVcREUTEagTGGNOOb4IA3MghywFjjNmer4JAREhYEhhjzHZ8FQRWIzDGmB35KgiE1NQI9nUZaoB77rmH+vr6Ti6RMcbsOV8FQapqBBYExpierLusNdQlUtVHkLwM9WmnnUbv3r156qmnaGpq4rzzzuMnP/kJdXV1XHTRRZSVlRGPx/nhD3/Ixo0bWbduHSeddBLFxcW8+eabnV42Y4zZnQMvCF68BTZ81uGuAS1x90U4uHfn7HsYnHHXTncnL0P9yiuv8Mwzz/DRRx+hqkyZMoV33nmH8vJy+vfvzwsvvAC4NYjy8/P5zW9+w5tvvklxcfHelckYYzqJr5qGAJTU9ha/8sorvPLKKxx55JEcddRRLFq0iKVLl3LYYYfx6quv8v3vf58ZM2aQn5+f0nIYY8yeOvBqBLv4zX1TRR1NLQkO6ZubssurKrfeeivXXXfdDvtmz57N9OnTue222zjllFO4/fbbU1YOY4zZU76qEYgIiRTUCJKXoT799NN56KGHqK2tBWDt2rVs2rSJdevWEY1GueKKK7j55puZPXv2Du81xph0OPBqBLsQIDWjhpKXoT7jjDO47LLLmDBhAgA5OTk8/vjjLFu2jJtvvplAIEA4HOb+++8H4Nprr2Xy5Mn079/fOouNMWkhPW3tnXHjxumsWbO227Zw4UJGjhy52/eurWygsr6Z0f17dvv8nn6/xhjTSkQ+3tkKz75qGrKZxcYYsyNfBUHrzOKeVgsyxphUOmCCYE8+3FufW9yTY8BCzBjT2Q6IIMjMzKSiomK3H5KpfG5xV1BVKioqyMzMTHdRjDEHkANi1FBpaSllZWWUl5fv8rjaphiV9S0EqjIJtlYPepjMzExKS0vTXQxjzAEklc8sfgg4G9ikqmM62D8C+AtwFPADVf3Vvl4rHA4zdOjQ3R731Kw1/Pe0ucz475MY2Cu6r5czxpgDSiqbhh4GJu9i/xbgW8A+B8DeioTct9sUsycXG2NMq5QFgaq+g/uw39n+Tao6E2hJVRnay/QWm2uKxbvqksYY0+31iM5iEblWRGaJyKzd9QPsSmuNoLHFagTGGNOqRwSBqk5V1XGqOq6kpGSfzxMJWY3AGGPa6xFB0Fkyw14fgdUIjDGmja+CwGoExhizo1QOH30CmAgUi0gZ8CMgDKCqD4hIX2AWkAckROQ7wChVrU5VmdpqBDZqyBhj2qQsCFT10t3s3wB06cyoiDdqqLHFagTGGNPKZ01DViMwxpj2fBUEbfMIrLPYGGPa+CoIts0jsKYhY4xp5asgCAWEgFjTkDHGJPNVEIgImeGgDR81xpgkvgoCcM1DtsSEMcZs48MgsBqBMcYk810QZIatRmCMMcl8FwRWIzDGmO0dEI+q3CPV62DtbAqDGTTF7Jm/xhjTyj81gjUfwt8vZ4BU2DwCY4xJ4p8gCLlaQHYoZvMIjDEmiY+CIAJANBCzJSaMMSaJj4IgC3BB0GidxcYY08ZHQdBaI2i2GoExxiTxURC4PoJowPoIjDEmmX+CIOyCIEtaaLJRQ8YY0yZlQSAiD4nIJhGZt5P9IiK/E5FlIjJXRI5KVVmAthpBprRYjcAYY5KkskbwMDB5F/vPAIZ7f64F7k9hWdqCIEtaaI4niCc0pZczxpieImVBoKrvAFt2ccg5wKPqfAAUiEi/VJWnNQgitADQbLUCY4wB0ttHMABYk/S6zNu2AxG5VkRmicis8vLyfbuaN2ooQjOArTdkjDGeHtFZrKpTVXWcqo4rKSnZt5MEghAIt9UIbAVSY4xx0hkEa4GBSa9LvW2pE8okQ61GYIwxydIZBNOA//BGDx0HVKnq+pReMZxJhlcjsJFDxhjjpGwZahF5ApgIFItIGfAjIAygqg8A04EzgWVAPfC1VJWlTSiTsDYB2AqkxhjjSVkQqOqlu9mvwPWpun6HQhHCbU1DViMwxhjoIZ3FnSaURTDhgsCGjxpjjOOzIIgQSrimIessNsYYx2dBkEmwNQhs+KgxxgC+C4IIwbjXNBS3IDDGGPBbEISzCFiNwBhjtuOvIAhFCMQbAesjMMaYVj4LgkwC8dbOYqsRGGMM+DAIJGZBYIwxyXwXBMRam4YsCIwxBnwXBBEk1khGKGATyowxxuOvIAhnQSJGNKjWWWyMMR5/BYH3cJrcUMyahowxxuOzIHCPq8wNJaxpyBhjPD4LAlcjyA5ajcAYY1r5LAiyAMgJxmiy5xEYYwzguyDw+giCMVtryBhjPD4LAtdHEA222FpDxhjj8VcQhF0QZAfiNnzUGGM8KQ0CEZksIotFZJmI3NLB/sEi8rqIzBWRt0SkNJXlaa0RZAdarGnIGGM8KQsCEQkC9wJnAKOAS0VkVLvDfgU8qqqHA3cAd6aqPEBbH0FWwJqGjDGmVSprBMcAy1R1hao2A08C57Q7ZhTwhvf1mx3s71xejSBLbPioMca0SmUQDADWJL0u87Yl+xQ43/v6PCBXRIran0hErhWRWSIyq7y8fN9L1BYELTahzBhjPOnuLL4J+JKIfAJ8CVgL7NCLq6pTVXWcqo4rKSnZ96t5QZApLdZZbIwxnlAKz70WGJj0utTb1kZV1+HVCEQkB7hAVStTViKvj8AFgdUIjDEGUlsjmAkMF5GhIpIBXAJMSz5ARIpFpLUMtwIPpbA8bvVRLAiMMSZZyoJAVWPADcDLwELgKVWdLyJ3iMgU77CJwGIRWQL0AX6WqvIAEHQ1gog2E08oMRtCaowxKW0aQlWnA9Pbbbs96etngGdSWYbtBAIQzCAiLQA0xxOEgunuJjHGmPTy36dgKIsMmgFsLoExxuDLIIiQoS4IbHaxMcbsYRCIyLdFJE+cP4vIbBGZlOrCpUQok7BajcAYY1rtaY3gP1W1GpgEFAJXAnelrFSpFIpsCwKbS2CMMXscBOL9fSbwmKrOT9rWs4STagQ2hNQYY/Y4CD4WkVdwQfCyiOQCPfNTNJRJKNEEWBAYYwzs+fDRq4GxwApVrReRXsDXUlesFAplEmpuBKxpyBhjYM9rBBOAxapaKSJXALcBVakrVgqFMgkmvFFDViMwxpg9DoL7gXoROQK4EVgOPJqyUqVSKEIw3lojsCAwxpg9DYKYqirueQF/UNV7gdzUFSuFQpkErI/AGGPa7GkfQY2I3IobNnqit1BcOHXFSqFQJoG4NQ0ZY0yrPa0RXAw04eYTbMAtKf3LlJUqlcKZBGLWWWyMMa32KAi8D/+/AvkicjbQqKo9tI8gE2ntI7CZxcYYs8dLTFwEfARcCFwEfCgiX0llwVImFIGY6yOwtYaMMWbP+wh+AIxX1U0AIlICvEZXLiHdWUJZiMYJErcagTHGsOd9BIHWEPBU7MV7uxfvcZU5AXtusTHGwJ7XCF4SkZeBJ7zXF9PugTM9hvcA+9xQ3EYNGWMMexgEqnqziFwAHO9tmqqqz6WuWCkUdkGQE4zZPAJjjGEvHlWpqs8Cz+7NyUVkMvBbIAg8qKp3tds/CHgEKPCOucV7vGXqJNUIrGnIGGN2EwQiUgNoR7sAVdW8Xbw3CNwLnAaUATNFZJqqLkg67DbcQ+3vF5FRuOamIXv3Leyl1j6CkNUIjDEGdhMEqro/y0gcAyxT1RUAIvIkbomK5CBQoDVM8oF1+3G9PRPKAiBHWqyPwBhjSO3InwHAmqTXZd62ZD8GrhCRMlxt4JsdnUhErhWRWSIyq7y8fP9KFXZBkBtqthqBMcaQ/iGglwIPq2op3tPPvHWMtqOqU1V1nKqOKykp2b8rZmQDkBtotj4CY4whtUGwFhiY9LrU25bsauApAFV9H8gEilNYprYgyJZmaxoyxhhSGwQzgeEiMlREMoBLgGntjvkcOAVAREbigmA/2352IxwFIEearGnIGGNIYRCoagy4AXgZWIgbHTRfRO4QkSneYTcCXxeRT3GT1a7ynnuQOm01gkZbYsIYY9iLeQT7wpsTML3dttuTvl7AtklqXcOrEUSl2RadM8YY0t9Z3PVCEZAgWTTR1GKdxcYY478gEIGMbLJotD4CY4zBj0EAEI6SRaONGjLGGPwaBBlRImqjhowxBvwaBOFsMhMNNMcTJBKpHaRkjDHdnT+DICNKRN1zi23kkDHG73waBNlkJLwH2FvzkDHG5/wZBOEo4UQDgK03ZIzxPX8GQUY24bjXNGQ1AmOMz/kzCMJRQm01AgsCY4y/+TMIMrIJxeoBbL0hY4zv+TcI4g0ICRs1ZIzxPX8GgbfwXCbNNNp6Q8YYn/NnEHhLUUdpYmtdc5oLY4wx6eXPIPBqBFnSxMbqxjQXxhhj0sufQZDhgiAv0MyG6qY0F8YYY9LLn0EQdk1DpdkJNlmNwBjjcykNAhGZLCKLRWSZiNzSwf67RWSO92eJiFSmsjxtvD6CftEEGywIjDE+l7JHVYpIELgXOA0oA2aKyDTv8ZQAqOp3k47/JnBkqsqzHa9pqG9WnBkWBMYYn0tljeAYYJmqrlDVZuBJ4JxdHH8p7gH2qec1DZVE4myyPgJjjM+lMggGAGuSXpd523YgIoOBocAbO9l/rYjMEpFZ5eXl+18yr0ZQHIlT2xSjtim2/+c0xpgeqrt0Fl8CPKOqHc7uUtWpqjpOVceVlJTs/9W84aO9wi0ANoTUGONrqQyCtcDApNel3raOXEJXNQsBZOQAkB9yk8k2VlkQGGP8K5VBMBMYLiJDRSQD92E/rf1BIjICKATeT2FZthfKgECIvIAXBDUWBMYY/0pZEKhqDLgBeBlYCDylqvNF5A4RmZJ06CXAk6ratQ8PDmeT4wXBhirrMDbG+FfKho8CqOp0YHq7bbe3e/3jVJZhpzKihOMN5EZC1kdgjPG17tJZ3PXCUWipp09+pgWBMcbX/BsEGVForqNPXsRmFxtjfM3HQZDjBUGmTSozxviaf4OgtWkozzUNJRJd21dtjDHdhX+DICMKzfX0zcskllAq7AE1xhifSumooW4tnA0trmkI4MF3V9AcS3DtFw+iX35WmgtnjDFdx79B4NUIhhS75Sb++PYKABZvqOHxq48lEJB0ls4YY7qMj4MgG5rrGNE3j39/8wSKcyK8uXgTt/7jMx77YDVf/cKQdJfQGGO6hH/7CMLZEGuARIIxA/Lpm5/JJeMHMvHQEu58cSErymvTXUJjjOkS/g0CbylqWurbNokIv7jgcCKhIDc+/SlxG0lkjPEB/wZBeMcgAOiTl8kd54zmk88rmfrOiu3fU7MRYs3MWrWFilqbe2CMOTD4u48AoLluh11TjujPy/M3cPerS0iocuTAAo7pA6HfH8X6UVdz4YfHMm5wIU9dNwER61Q2xvRsFgTtagTgmoh+eu5hfL7lQ3758mIAftZ3Bpc311I791+EgxOYuWorL3y2nrMP79+VpTbGmE7n46ahndcIAHplZ/Dvb57InNtP48dnj+TYLf8EYHhiBQ+eP4iR/fK4c/oiGls6fKiaMcb0GP4Ngl5DAYG5T23bVr0O2j0WoSCawVUDN3BwYB2PxicB8MXgZ/zoy6NYW9nQNv/AGGN6Kv8GQdEwOPYbMPNPsPp9eOsu+M1IeP/eHY+d9ReI5DH52w+g0WJY9jrHHVTE2Yf34963lrFyc8e1CmOM6Qn8GwQAJ98GBYPg8fPhrTshWgxv/BS2JP2WX1UGC/4Jh19E7+IiZNjJsPwNSCS4/exRRIIBfvj8PLr6AWvGGNNZ/B0EkRz48u8g3gInfA+ueweCYfjXt7c1Eb1+h/v7C99yfx98CtRvhg2f0jsvk/8+YwTvLtvMP+esS8/3YIwx+ymlQSAik0VksYgsE5FbdnLMRSKyQETmi8jfUlmeDg07CW5dA6f+CPIHwGk/gZXvwPSbXJPR3L/DhOuhcLB3/Mnu7yUvA3D5MYMYMyCPe15bYhPQjDE9UsqCQESCwL3AGcAo4FIRGdXumOHArcDxqjoa+E6qyrNL4aTVRo+6Co67HmY+CA+fBdklcMJ3t+3P6Q3DToGPpkJTLYGA8P8mHsyqinpeXbChy4tujDH7K5U1gmOAZaq6QlWbgSeBc9od83XgXlXdCqCqm1JYnj0TCMDkn8Mlf4PcfnD6nZCZt/0xE2+F+goXBsDpo/syqFeUP76zwvoKjDE9TiqDYACwJul1mbct2SHAISLyfyLygYhM7uhEInKtiMwSkVnl5eUpKm47I86C782Hwy/ccd/A8TB8Erz3O2isJhgQrjlxKJ98Xsms1Vu7pnzGGNNJ0t1ZHAKGAxOBS4E/iUhB+4NUdaqqjlPVcSUlJV1cxJ2YeCs0bHUdy/VbuPDogRRGw/zq5cX22EtjTI+SyiBYCwxMel3qbUtWBkxT1RZVXQkswQVD9zfgKPjSLW5o6e+PJmvN23x/8gg+XLmFv7y3Kt2lM8aYPZbKIJgJDBeRoSKSAVwCTGt3zPO42gAiUoxrKuo5U3VPutUNOY3kwlt3cfH4gZw6sje/eGkRH6/eYstPGGN6hJQFgarGgBuAl4GFwFOqOl9E7hCRKd5hLwMVIrIAeBO4WVUrUlWmlOg7Bg67EMpmIY1V3Hn+4eRGQlxw//uM+OFLfOuJT7qsAzkWT/DrVxazqaaxS65njDkwpLSPQFWnq+ohqjpMVX/mbbtdVad5X6uqfk9VR6nqYar6ZCrLkzLDTgaNw6oZlORGeP764/nFBYfxlaNLmfbpOt5c3DWDoT5ZU8nv31jGc7Pbt8AZY8zOpbuz+MBQOh4yctzSE8DAXlEuHj+IO88/jINKsvnpCwtpiSdSXoy5ZVUAzFtXnfJrGWMOHBYEnSGUAUNObAuCVuFggB+cOZIV5XXc/9ZyYikOg8/KKgGYt7YqpdcxxhxYLAg6y7CTYeuq7ResA04e0ZuTDi3hN68uYcJdb3D7P+fxyvwN1DS2dHoR5noBsHJzXUrOb4w5MFkQdJbWNYja1QpEhD9eOY4HrjiaowYV8PSsMq597GMm3PkG97y2hPKaJjZUNVJVv38f3DWNLawor+OoQW4axnxrHjLG7CH/PqqysxUNg4LB8PEjMPYKCGe27coIBZg8pi+Tx/SlKRZn9upKHnlvFfe8tpR7XlvqjgkGuObEoVx/0sFkR0Jsrm1ixtJyNlU3ccVxg8mO7Pqfat5a98F/+bGDmf15JfPWVnHcQUWp+36NMQcMC4LOIgKT74QnL4PpN8KUP7ht7URCQSYMK2LCsCI+XVPJzFVbyI6EmLlyC/e9tZyp76xAYbuVTJ+atYY/XHYU0YwgTbEEw3vnIO3O/dla1z9w0oje9M3LtBqBMWaPWRB0phFnwYk3wYxfQWMVhKPQbywcex0EgjscfsTAAo4Y6JpyLj1mEFdMGMwr8zcSDEBeZpgJw4qoaYzx7Sc/4Yzfzmh734VHl/K/544hM7ztnHPLqigtzKJXdgZjBuTxmXUYG2P2kAVBZzvpf6B6LSx/0334z/07LJwG5z0AhUN2+dajBhVy1KDCHba/8K0Tef6TtRRGM1ixuY7n3p7JjCU/4t2Dvksot4Rzxw7gs7VVHF6aD8CYAfm8vmgT9c0xohn2T2yM2TX7lOhsgaD70Af3lLO5T7mH3Px+HBxxMUy4AXqP3KtT9snL5LovDWt7/dWNP6ffqjdZsmwAv2s6mz+/uxKAS8YPAuCwAfmoug7j8UN6dc73ZYw5YFkQpJKI+/Afcjy8ew988hh88jiUjITSo6G5zj0mM5LnnoB21H+4B+HM+Sus+QhO/iHk9dv+nOvn0m/VNJAA1xd+xJVX383jH37OC3PXc+rI3gAcXlpARijANx77mG98aRiXHjuInN10Nhtj/Et62oNUxo0bp7NmzUp3MfZNbTnMfw4WPA8Vy1wABMPQVOOakyTonoBWvRYkAFm93CM0N8yDTQtgxNmweDpsmAsn3giv3AbXvA6l43a41Jw1lfz6lcXMWLqZaEaQM8b044ThRRzaJ49D++YSDHidzQv+6UY79R/bxTfDGNOVRORjVd3xwwILgu5jy0r44D7YvASO/S/Xn/D0V6F8EYQy3Yf15sXu2Ek/c7WHXx0CYy+Ds3+z09PO/nwrT81cw7/nrqe2KQbA0OJs/t/EYXx5eITM344iMfBY3jj2IfKjYcYNLtxhRJIxpuezIOipmuth3Sfut/WMbPf15x/AuKvdshb/uBaWvARXPgfRIog1QyIGJSPcIzeTtMQTrNxcx6drKvnL/61iwfpqrg6/zA+DjxAjwNGND85fNcUAABS9SURBVFBFDiP65nLRuIFMGt2H0sJomr5xY0xnsyA4UK2cAY+cveP2ISfCufdBwaBt2+oqIKsQAgFUlXeXbWb4c2cSbdxAXqKaBRN+xWe9TuexD1a3TU4b3juHcUMKGVaSQ2Y4iAINzTHqmuLUN8fIyghx7NBejOmfTyAAzbEEW+qaWVvZwJKNNVTUNjOqfx7jhvRiQEFW19wTY0yHLAgOZOs/haoy99jMUCbUboQ3f+76GA6ZDMXDYeU7sGoGHHomXPgwhCKwfi788USY/At49zcwaAJc9Ajg1ip6Zf4G3l9Rwcert1LTGNvhslnhIM3xBJJooZAaytlx2Gs4KLTE3f+vIwcVMGlUXxpb4myqaWJTdSM1TTFOPLiYKWP7M6hX1JqkjEkhCwK/2boKXv2RG3lUsw56HeQ+6Of8FQ4+DSb9L7x/r5vjcONieO3HMO8fcNNieONnULkaDpoIw04mUTCUmuY4Td7T1qKREFnhIMGAUNvQRNOjX6Fgw/u8OeZOyvqeSlFOhN65EQ7pk0tuZohFG2qYsXQzz3+ylsUbawAozsmgJDeTcFDals7OjYQYVBRlcFGU/vlZbKhuZFVFHXmZYQYWRskJJfjakv/H69HJPN78JcYNKeTGSYdSnBNJyy02pqexIPCzxmr3KE0Rtw7Sv74NeP/mo8+HC/8Ci1+CJy52w1rLF0LeADdyCVzz0ujz4YTvQDgb5jwOtZvg6Kvgo6kw49euI7tqDZx9t9veqmotrHgTKpahw09na9FR5GaFCQe39V+Uba3ntQUbWbm5jtVb6vm8op61lQ30zoswpCibmsYYZVsbmBR7g59zL+VSxH+XPsaM5VVkhYOcOqoP/QsyiSWUTdVNDC6Kctmxg+idu22tp91qqoHNS91zqDvLlpXu3nUwo9yYdLAgMNusnQ1bVwICQ78I2cXQ0gC/GAqxBjjzVzD+Grec9vI3YNlrsORlyCpww10rV7vzBCMQb4KjvurWWHrqq7DsVTj+23DCd+Hl21xogLsW6j4Y+xwGvUfA+K/vOEdiZ1ThgRPdtZuq4bypLOt3Fr9+ZTFzy6rYUN1IUITinAzWVTUSDgrDSnJobIkTCgYoys4gNzNMKCD0ysng8AH5DC7KRlUpzo1wyDvfcsN6vzYdBn+BmsYWGlsSlOTuY22jfAncdxyc/jM47r/27RzGdLK0BYGITAZ+CwSBB1X1rnb7rwJ+CbQ+W/EPqvrgrs5pQZAic592I5NGnLnjvg2fwet3QEMlfPFmKD7YTZBrrILzp7o+h3gLvPh9mPVnCGW5kJhwPRx+iQuAhf9ycyAqlrk/oUw48XtQdLB7b8NWaK6FMV+BgoHuuomEG/204m14dApM+b1r0gqE4BvvulpOcx2Jl/4H6XsYcsw1rNxcxz9mzGFNZSOJzF60xBNU1DZT0xQjkVDWVzVQndTncZCs47XIzQiwKdiPc+K/YEOj+y3+8NJ8Jo3qQ7/8LEpyI4zsl0dJboSq+hbWVTUwtDh7u/We2vz7e+4+lB4D17zqfStKIGB9ICZ90hIEIhIElgCnAWXATOBSVV2QdMxVwDhVvWFPz2tB0M199Cf32/Vpd3Q40Q2AiuXw0i2w9JUd94Wz4Ys3wuZlMO9Zt7y3KtRvhu/Mg8+ehmk3uLkUg46Df3/XTbBD3DDavAHwlzNcWHxtunt/ElVldUU96yobCASEXq9+h0HrX+J7Lf/FfeHf8kHReXx62G3EgZfnriV7wwecGpjNobKG/0uM4c3Q8SxsKgYgFBAO6ZNLTiREKCgU50QYkt3MDXOmoAiRRANXFjzCwtocKuqaGNM/n4vGD+S0kX3om79909Wm6kaikZDNADcpk64gmAD8WFVP917fCqCqdyYdcxUWBP6k6gIh3uRmVEd7uRrBCzfB8tddIIw+z9Ue1nwAp9zuZlPHmuCBE9zEO4CMXDjnD/DWXVC3CYIZkIiDJtzXV/3bhUGsCd66083SPuR0GHICNNXCXyaj466m8dQ7yXr9B/Dh/a5DfexlMOM3sPEzNBihIXcw0Up3zcX9prDyiBuZW+mW+26KxWmJK5tqGjmr5hluCf6VHwS/w8/i9/BYrxuYP+BiCqIZvLV4E4s2uA7zPnkRSguj5ERCrNxcx+db6olmBDn3yAFMPKSEvKwwZVsbeG/5ZtZVNhAMCLG4UtccoyArg7MO78fk0X0pzM5I17+g6WHSFQRfASar6jXe6yuBY5M/9L0guBMox9Uevquqazo417XAtQCDBg06evXq1Skps+kGVN2Q2F5DIdOtpkpDpeufaJ0kF2uCTQuhfLGrdRQNc+3yfzrJLdlx1XRA4ZEvu47gMRe4JTrWfwr5g6Dq823XC4Th23Mgv9QFyEdT4fX/hZY6d+zJt8HIs12zWVUZfPhH+OB+1ywVynSdwcdd7/pGatbDw2e7pq2vTYc/jIfcvnDJ3+DtX6CRPJb2OYNZ62OsXb2U+S192NIUpG9eJscM7cWiDTX869N1NMW2Pdu6V3YGw0qySSgERciOBFldUc+KzXUAHNonl8NK8+mdG6FXdgYZoQAiQn1TjFAwwOk2MdB4unMQFAG1qtokItcBF6vqybs6r9UIzE5tWgThLLeAH7hhtO/9AT59wjUVnXufm0tRvgg2znezsAuHuCamZJVr3Czu4ZO2e9Jcm4rl8PFfIB5z11jyIuT2h9oNgMAVz7hHl75+h+tL6T3SBZEmtj9P79Hw1Wmuw95T1dDC5xX11DS2UJidwaF9cnfoW1BV5q2t5q3Fm5i1eiuLNlRTUdtMLNHxz/JhA/JRlPrmOKGAkB0JceTAQo47qBf98rMoiIbJj4bJjYRIqJuFHvECxRw4um3TULvjg8AWVc3f1XktCMxea65zE+zCKZrdvGi668QeeAyMv9rVLgDWzYGpX3LNXBc9AiWHwoJpXm0i4kZWFQ52TV5bVrpaSDADBh4LB5/a4RPuAFfLWTQdWuph7OUQyiCRUGqbYzTHEiQSSjQSYmtdM899spb3lm8mmhEiKyNIPK5srW/mkzWVNMe2D6aINNOkrqkpOyNI3/xMciIhIqEgxbkZ9MvPIlG3hbFlj7MwejSbisZTnONqIgMLoxzaN5eSnIgbJAaEFk2juaGWNQOngAilhVEKo+G2gIknlJZ4ouMOd9Pp0hUEIVxzzym4UUEzgctUdX7SMf1Udb339XnA91X1uI7O18qCwPQYqjDzQVfj6HvYjvtXvgN/u9h9oOOFQ6wJUBcEw06Gz9+HravdMYmY60+pXguxRneOkpFw+k+hdLwLnM1LoGKp6/8QgQFHuwB86xeuE7/kEBh8PE1Hfo15Db3YUlVLzqqXGLjqWQZs+ZANuaNZ1HcKuVsXMGLLGwQ0Rr1EWSWlzGvpz7mBGRRQQ7XkcmX41yypz+FqfY5jAosolBpWax+eik9kcuAjLgu9CcBr8SP5dewiAiQYklHNuKz1DE2spm/TSuIqPB29mIUFJ7G5uo5YYx25hUWUFkQpLcyif4F76l5OJERjLE5zLEE0I0ReZoiczBDZkRCq6maw12wkZ+WLBPP6Eh40nsasPjS0xImEAuRlhsnNDBHy5rC0xBMkVAkHAt1/NFddBWR6KxXvh3QOHz0TuAc3fPQhVf2ZiNwBzFLVaSJyJzAFiAFbgP9S1UW7OqcFgTmgVK+Hhi1u9nc4yw2l/Wiq6/xuqnaT9UpGuD6KQAg07p5ZMfo813fywo1QXebOFQhDoqXj6wQjMOZ81+xVNtOFysGnQtlHbuhu/kDXbLb8dddBH46619kl0FjphhBvWuBqKxNucAse9j8SzS5GFjxPQ/EYqqSAgsrPyGxxs8XnDPlP4lkljF18N8FE83bF2Rzszdacg+nVvJ6ihpVUSR65WkuABNWBAlZLf9bHciiP57JGS1itffhce9NAhEmBWZwUnEMxVeRJPRu0kK2ay4TAAsISb7vGR4lDeTQ2iSKp5ouBudSSxXIZwirtzfpYHkcEljM5OJM4AT7WkZRLEZmBFnpJLb3ZSlBga6CQlkCEbBrorVsYkvicMDGWZoxgc6gvRYkKcrUGESFMjIL4FgIkWJJ7LOujh3Jw3WwGNCyhLlRIfaiA3JYKorGtVEYGUBXpS3HjKvrULyceCNEUzKUplEtzKIfmcC6JQIT+1XMorl1MczCH9UXH0nz4FQw/4fx9+q9mE8qM6Wkaq9zqs7ubdNdc52oWmxa6D+w+Y1xwZOa51WjLPnIzvI+8fFuTVc0G13cx71n30KQjr3RLigSCbu7Gxs9cMEVyt79WrNmtegsw52/wvDdZbtJP4QvfdF+3NLoVcXP6wOAJblvFcjeRMSPqgqXk0G0DARJxt9TJyhmufJEcN8t7ywq0fgtau5FAw5Ydvu3aojHURgfRGIgSbdhAVuNGtvQ9gQ3DvkJzfTXZ6z/kkDVPk9PgpihVRQch8WbymjZsd56N2SNISIA+tYsJ4EIkQYCaUC8UITe2hSBxmiVCdbCAteHBxDXAwc0LyUtUUSn5VAfyUIUYQbZIASFt4bDEQkIkaCDCfA4in1oK1K3JVUUOpWykP+Wsoh8LdAiCkks9udSRSwN5Ukc2jSzQwbwdP4IBUs7E4KcsGXgxE6+5a4f7sScsCIwxnUsV3vu962wfNSW112qsdp3yW1dBfQUMO2m3z/8GXGf+6nchr9RNggRXi6pa48KwaJgLPHCB2lTrgi4jF4LefI5EwhuK3G5+hyrEm11zXkfqt7hmun5jOx5w0HrudsvFu1Mr8YQSVyWRgFgiQSIB8USCjECcnOi+jQKzIDDGGJ/bVRDsGEfGGGN8xYLAGGN8zoLAGGN8zoLAGGN8zoLAGGN8zoLAGGN8zoLAGGN8zoLAGGN8rsdNKBORcmBfH0hQDGzuxOKkgpWxc1gZO4eVcf91l/INVtWSjnb0uCDYHyIya2cz67oLK2PnsDJ2Divj/uvu5QNrGjLGGN+zIDDGGJ/zWxBMTXcB9oCVsXNYGTuHlXH/dffy+auPwBhjzI78ViMwxhjTjgWBMcb4nG+CQEQmi8hiEVkmIrekuzwAIjJQRN4UkQUiMl9Evu1t7yUir4rIUu/vwjSXMygin4jIv73XQ0XkQ+9e/l1EMtJcvgIReUZEFonIQhGZ0A3v4Xe9f+N5IvKEiGSm+z6KyEMisklE5iVt6/C+ifM7r6xzReSoNJbxl96/9VwReU5ECpL23eqVcbGInJ6uMibtu1FEVESKvddpuY+744sgEJEgcC9wBjAKuFRERqW3VADEgBtVdRRwHHC9V65bgNdVdTjwuvc6nb4NLEx6/QvgblU9GNgKXJ2WUm3zW+AlVR0BHIEra7e5hyIyAPgWME5VxwBB4BLSfx8fBia327az+3YGMNz7cy1wfxrL+CowRlUPB5YAtwJ4PzuXAKO999zn/eyno4yIyEBgEvB50uZ03cdd8kUQAMcAy1R1hao2A08C56S5TKjqelWd7X1dg/sAG4Ar2yPeYY8A56anhCAipcBZwIPeawFOBp7xDkl3+fKBLwJ/BlDVZlWtpBvdQ08IyBKREBAF1pPm+6iq7wDtnwy/s/t2DvCoOh8ABSLSLx1lVNVXVDXmvfwAKE0q45Oq2qSqK4FluJ/9Li+j527gv4HkETlpuY+745cgGACsSXpd5m3rNkRkCHAk8CHQR1XXe7s2AH3SVCyAe3D/mRPe6yKgMukHMd33cihQDvzFa756UESy6Ub3UFXXAr/C/Wa4HqgCPqZ73cdWO7tv3fVn6D+BF72vu00ZReQcYK2qftpuV7cpYzK/BEG3JiI5wLPAd1S1OnmfuvG9aRnjKyJnA5tU9eN0XH8PhYCjgPtV9UigjnbNQOm8hwBeO/s5uNDqD2TTQVNCd5Pu+7Y7IvIDXPPqX9NdlmQiEgX+B7g93WXZU34JgrXAwKTXpd62tBORMC4E/qqq//A2b2ytLnp/b0pT8Y4HpojIKlxz2sm49vgCr4kD0n8vy4AyVf3Qe/0MLhi6yz0EOBVYqarlqtoC/AN3b7vTfWy1s/vWrX6GROQq4Gzgct02Gaq7lHEYLvQ/9X52SoHZItKX7lPG7fglCGYCw71RGhm4DqVpaS5Ta3v7n4GFqvqbpF3TgK96X38V+GdXlw1AVW9V1VJVHYK7Z2+o6uXAm8BX0l0+AFXdAKwRkUO9TacAC+gm99DzOXCciES9f/PWMnab+5hkZ/dtGvAf3qiX44CqpCakLiUik3HNlVNUtT5p1zTgEhGJiMhQXIfsR11dPlX9TFV7q+oQ72enDDjK+7/abe7jdlTVF3+AM3EjDJYDP0h3ebwynYCres8F5nh/zsS1w78OLAVeA3p1g7JOBP7tfX0Q7gdsGfA0EElz2cYCs7z7+DxQ2N3uIfATYBEwD3gMiKT7PgJP4PosWnAfVlfv7L4Bght5txz4DDcCKl1lXIZrZ2/9mXkg6fgfeGVcDJyRrjK2278KKE7nfdzdH1tiwhhjfM4vTUPGGGN2woLAGGN8zoLAGGN8zoLAGGN8zoLAGGN8zoLAmC4kIhPFW8XVmO7CgsAYY3zOgsCYDojIFSLykYjMEZE/insmQ62I3O09V+B1ESnxjh0rIh8krY/fuob/wSLymoh8KiKzRWSYd/oc2fb8hL96s42NSRsLAmPaEZGRwMXA8ao6FogDl+MWi5ulqqOBt4EfeW95FPi+uvXxP0va/lfgXlU9AvgCbvYpuFVmv4N7NsZBuHWHjEmb0O4PMcZ3TgGOBmZ6v6xn4RZfSwB/9455HPiH9zyEAlV929v+CPC0iOQCA1T1OQBVbQTwzveRqpZ5r+cAQ4B3U/9tGdMxCwJjdiTAI6p663YbRX7Y7rh9XZ+lKenrOPZzaNLMmoaM2dHrwFdEpDe0Pcd3MO7npXW10MuAd1W1CtgqIid6268E3lb3xLkyETnXO0fEW6femG7HfhMxph1VXSAitwGviEgAt6rk9biH3hzj7duE60cAt1zzA94H/Qrga972K4E/isgd3jku7MJvw5g9ZquPGrOHRKRWVXPSXQ5jOps1DRljjM9ZjcAYY3zOagTGGONzFgTGGONzFgTGGONzFgTGGONzFgTGGONz/x/PGg2vxY/SSAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Model"
      ],
      "metadata": {
        "id": "en7GBfldkDQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/gdrive/My Drive/NIOSH Project/Nerual_Network_Model')"
      ],
      "metadata": {
        "id": "tUCXl--2kFhW"
      },
      "execution_count": 131,
      "outputs": []
    }
  ]
}